[
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Quốc Bảo\nSố điện thoại: 0969197845\nEmail: baonqse181700@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: Trí tuệ nhân tạo (AI)\nMSSV SE181700\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Cách một khách hàng giảm 28% tổng chi phí sở hữu (TCO) cho việc lưu trữ với Amazon FSx for NetApp ONTAP bởi Sachin Bawse và Vishnu Vashist | vào ngày 08 tháng 9 năm 2025 | trong chuyên mục Advanced (300), Amazon FSx for NetApp ONTAP, Best Practices, Healthcare, Technical How-to | Permalink\nCác tổ chức có nhiều chi nhánh thường gặp thách thức lớn trong việc quản lý hệ thống tệp phân tán, đặc biệt khi sử dụng hạ tầng tại chỗ (on-premises) truyền thống. Việc duy trì khả năng chia sẻ tệp mượt mà giữa các vị trí địa lý khác nhau, đồng thời đảm bảo tính bảo mật, hiệu quả trong quản lý dữ liệu và xác thực người dùng đáng tin cậy, ngày càng trở nên phức tạp trong bối cảnh số hóa hiện nay.\nAmazon FSx for NetApp ONTAP giải quyết những thách thức này bằng cách cung cấp một giải pháp cloud-native được quản lý hoàn toàn, mang lại khả năng lưu trữ tệp hiệu năng cao với tích hợp sẵn tính năng sao chép dữ liệu (replication), đồng bộ tự động và bộ nhớ đệm thông minh (intelligent caching).\nTrong bài viết này, nhóm tác giả chia sẻ cách một khách hàng đã triển khai FSx for ONTAP với cấu hình Multi-AZ, sử dụng NetApp FlexCache cho bộ nhớ đệm cục bộ và thực hiện di chuyển dữ liệu bằng SnapMirror. Trong quá trình này, họ thực hiện các bài kiểm tra hiệu năng, phân tích các đánh đổi trong thiết kế kiến trúc và đưa ra so sánh chi phí — cho thấy mức giảm 28% chi phí sở hữu tổng thể (TCO) so với giải pháp tại chỗ truyền thống.\nTổng quan giải pháp Kiến trúc cốt lõi của giải pháp xoay quanh việc triển khai Amazon FSx for NetApp ONTAP Multi-AZ cluster trải rộng trên hai Vùng sẵn sàng (Availability Zones), nhằm đảm bảo tính sẵn sàng cao và khả năng chịu lỗi. Các chi nhánh kết nối tới FSxN thông qua các kết nối VPN bảo mật, truy cập dữ liệu thông qua ONTAP FlexCache volumes được triển khai tại môi trường on-prem hoặc VMware. Các bộ nhớ đệm này giúp giảm băng thông và cải thiện tốc độ phản hồi nhờ phục vụ dữ liệu được truy cập thường xuyên ngay tại chỗ. Việc di chuyển dữ liệu được thực hiện bằng NetApp SnapMirror, đảm bảo sao chép dữ liệu nhất quán từ kho lưu trữ on-prem lên AWS.\n*Hình 1: Hệ thống tệp phân tán với kiến trúc Amazon FSx hoặc NetApp ONTAP.\nCác lớp giao tiếp và bộ nhớ đệm bao gồm:\nChi nhánh địa phương → FlexCache volumes (phục vụ dữ liệu nóng) FlexCache → FSx ONTAP origin cluster trên các AZ SnapMirror → sao chép dữ liệu lên FSx, duy trì hiệu quả lưu trữ Khách hàng cũng tiến hành so sánh hiệu năng: khi truyền một tệp 50 MB, ONTAP Select cache kết nối FSx đạt 26,09 giây, so với 24,20 giây trên máy chủ tệp cục bộ, cho thấy hiệu năng gần tương đương với lưu trữ tại chỗ. Cân nhắc về độ trễ và ghi lại FlexCache Tính năng ghi lại (write-back) của FlexCache đặc biệt hữu ích khi độ trễ (latency) giữa bộ nhớ đệm chi nhánh và cụm gốc vượt quá 8 ms. Trong điều kiện đó, bộ nhớ đệm giúp cải thiện hiệu năng ghi dữ liệu đáng kể.\nMột số yêu cầu thiết kế cần lưu ý:\nCPU \u0026amp; RAM: Mỗi nút trong cụm gốc cần ít nhất 128 GB RAM và khoảng 20 vCPUs để xử lý tải write-back. • Phiên bản ONTAP: Cụm gốc và cụm cache phải chạy ONTAP 9.15.1 trở lên để hỗ trợ write-back. • Giấy phép (Licensing): FlexCache (bao gồm cả write-back) đã được tích hợp sẵn, không cần mua thêm license. • Cluster peering: Cụm gốc và cụm cache cần được kết nối ngang hàng (peered), các server virtual machines SVMs cũng cần được vserver-peered với FlexCache bật. Những nguyên tắc này giúp đảm bảo bộ nhớ đệm hoạt động ổn định trong các mô hình chi nhánh phân tán.\nGiám sát và khả năng hiển thị Để có cái nhìn chi tiết hơn về hiệu suất và hoạt động của FSx \u0026amp; ONTAP ngoài dữ liệu mặc định trên Amazon CloudWatch, giải pháp sử dụng NetApp Harvest kết hợp với Grafana. Công cụ Harvest thu thập các chỉ số như hiệu năng, tỷ lệ cache hit, mức độ hiệu quả lưu trữ, và thống kê cấp volume, giúp quản trị viên có khả năng theo dõi chi tiết và chủ động tối ưu hóa.\nƯớc tính TCO so với on-premises Để định lượng lợi ích về chi phí, khách hàng đã mô hình hóa một kịch bản lai (hybrid) để so sánh giữa FSx for ONTAP (Multi-AZ, cấu hình SSD + capacity tier tỉ lệ khoảng 30/70, throughput ~256 MB/s) với hệ thống tại chỗ tương đương.\nKết quả cho thấy FSx for ONTAP giúp giảm ước tính 28% tổng chi phí sở hữu (TCO) so với giải pháp tại chỗ, nhờ giảm chi phí vận hành, tăng hiệu quả lưu trữ, và đơn giản hóa hạ tầng quản lý.\nKết Luận Amazon FSx for NetApp ONTAP là một giải pháp mạnh mẽ cho các hệ thống tệp phân tán, đặc biệt phù hợp với mô hình nhiều chi nhánh.\nThông qua triển khai Multi-AZ, FlexCache để lưu đệm cục bộ, SnapMirror để di chuyển dữ liệu, cùng hệ thống giám sát chi tiết, kiến trúc này mang lại hiệu năng gần như cục bộ, độ sẵn sàng cao, và giảm 28% TCO so với on-premises.\nChiến lược triển khai này cho thấy cách tích hợp lưu trữ đám mây hiện đại có thể khắc phục các hạn chế truyền thống về băng thông, tính nhất quán và độ phức tạp vận hành trong các hệ thống phân tán nhiều địa điểm.\nTác Giả Sachin Bawse Sachin là Kiến trúc sư Giải pháp Chuyên gia về Lưu trữ (GTM Specialist Storage Solution Architect) tại Amazon Web Services (AWS), nơi anh chuyên về tối ưu hóa các giải pháp lưu trữ, hỗ trợ di chuyển dữ liệu, và nâng cao hiệu suất khối lượng công việc cho khách hàng. Ngoài công việc, Sachin là một người đam mê khám phá, thích du lịch đến những điểm đến mới, tìm hiểu các nền văn hóa khác nhau và thưởng thức ẩm thực đa dạng. Vishnu Vashist Vishnu Vashist là Kiến trúc sư Giải pháp Thành công Đối tác (Partner Success Solutions Architect) trong bộ phận Đối tác (Partner Org) của AWS, nơi anh phụ trách các tài khoản thuộc lĩnh vực Y tế, Chăm sóc sức khỏe, Khoa học đời sống (HCLS) cũng như Du lịch, Vận tải và Logistics. Anh chuyên về di chuyển và hiện đại hóa hệ thống, hỗ trợ các dự án di chuyển quy mô lớn lên AWS và hướng dẫn khách hàng cùng đối tác về thiết kế kiến trúc và hạ tầng trên AWS. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Tự động hóa việc tạo vector embedding trong Aurora PostgreSQL bằng Bedrock bởi Domenico di Salvia và Andrea Filippo La Scola | vào ngày 05 tháng 09 năm 2025 | trong Advanced (300), Amazon Aurora, Amazon Bedrock, Technical How-to | Permalink\nVector embeddings đã thay đổi sâu sắc cách chúng ta tương tác với dữ liệu phi cấu trúc trong các ứng dụng sử dụng AI tạo sinh . Embeddings là các biểu diễn toán học giúp hỗ trợ tìm kiếm ngữ nghĩa (semantic search), hệ thống gợi ý (recommendations), và nhiều tác vụ xử lý ngôn ngữ tự nhiên khác bằng cách nắm bắt bản chất của văn bản, hình ảnh và nội dung khác dưới dạng mà máy có thể xử lý hiệu quả. Trong các ứng dụng sử dụng Retrieval-Augmented Generation (RAG) hoặc các giải pháp AI khác, việc duy trì embeddings được cập nhật khi dữ liệu thay đổi là rất quan trọng để đảm bảo kết quả tìm kiếm và gợi ý phản ánh đúng ý nghĩa.\nMặc dù Bedrock cung cấp các giải pháp RAG quản lý sẵn, nhiều tổ chức có yêu cầu cụ thể dẫn đến việc họ xây dựng giải pháp cơ sở dữ liệu vector tùy chỉnh, dùng PostgreSQL kết hợp extension pgvector. Trong bài viết này, tác giả trình bày nhiều cách để tự động sinh embeddings trong Aurora PostgreSQL khi dữ liệu được chèn hoặc cập nhật. Mỗi cách có những đánh đổi về độ phức tạp, độ trễ, tính đáng tin cậy và khả năng mở rộng để bạn chọn được chiến lược phù hợp cho ứng dụng.\nTổng quan giải pháp Khi dùng Aurora PostgreSQL với extension pgvector để tạo cơ sở dữ liệu vector, bạn cần một cơ chế tin cậy để sinh hoặc cập nhật embeddings khi dữ liệu thay đổi. Quy trình chung như sau:\nPhát hiện khi nào dữ liệu mới hoặc được sửa cần embedding.\nGửi nội dung đó đến mô hình embedding của Bedrock (ví dụ: Titan).\nNhận vector embedding.\nLưu chúng song song với dữ liệu gốc.\nTrong bài viết, tác giả sử dụng Titan làm mô hình nền qua Bedrock vì nó cung cấp embeddings chất lượng sản xuất mà không cần quản lý hạ tầng bổ sung. Bạn cũng có thể chọn các mô hình khác được hỗ trợ (ví dụ: Cohere Embed, Claude của Anthropic) hoặc thậm chí mô hình tùy chỉnh qua SageMaker hoặc thư viện mã nguồn mở.\nYêu cầu tiên quyết Trước khi triển khai bất kỳ cách nào, bạn cần đảm bảo:\nCó cụm Aurora PostgreSQL đã bật extension pgvector. Cấu hình IAM roles \u0026amp; policies cho phép truy cập Bedrock. Với các giải pháp dùng AWS Lambda, cấu hình VPC để Lambda có thể truy cập cả database và Bedrock. Với extension aws_ml, đảm bảo phiên bản database tương thích. Với pg_cron, extension đã được bật và cấu hình. Tác giả cung cấp kho mã nguồn GitHub kèm AWS CDK stack và code để triển khai môi trường demo. Các cách triển khai Bài viết mô tả năm chiến lược tự động hóa, mỗi chiến lược có ưu và nhược điểm:\nDatabase triggers + aws_ml extension (synchronous) Đơn giản: trigger trong database gọi aws_ml đồng bộ trong cùng transaction để sinh embedding. Có mã ví dụ (PL/pgSQL) cho generate_embedding và trigger store_embedding. Ưu điểm: tính đồng bộ tức thì, ít thành phần bên ngoài. Nhược điểm: làm chậm transaction, giới hạn mở rộng, xử lý lỗi phức tạp, rủi ro timeout. Database triggers + aws_lambda extension (synchronous) Trigger gọi một Lambda function đồng bộ, rồi function đó sinh embedding và trả kết quả. Tách logic embedding ra khỏi database nhưng vẫn giữ tính đồng bộ. Ưu điểm: linh hoạt hơn trong Lambda (tiền xử lý / hậu xử lý), quan sát lỗi tốt hơn. Nhược điểm: vẫn chặn transaction, có độ trễ Lambda (cold starts), yêu cầu cấu hình phức tạp. Database triggers + aws_lambda extension (asynchronous) Trigger kích hoạt Lambda bất đồng bộ, trả về ngay mà không chờ embedding hoàn thành. Sau khi embedding được sinh, Lambda sẽ ghi lại vào bảng document_embeddings (ví dụ qua RDS Data API). Ưu điểm: transaction không bị chặn, cải thiện throughput ghi. Nhược điểm: tính nhất quán chậm trễ (eventual consistency), phức tạp trong xử lý lỗi, embedding chậm. SQS queue + Lambda batch processing (asynchronous) Trigger gửi thay đổi vào hàng đợi SQS; Lambda consumer xử lý theo lô (batch) để sinh embeddings. Batching giúp giảm số lần gọi API, tăng khả năng retry, cải thiện độ chịu lỗi. Ưu điểm: khả năng mở rộng cao, robust trong xử lý lỗi, sử dụng API hiệu quả. Nhược điểm: độ trễ giữa thay đổi và embedding lâu hơn, độ phức tạp vận hành cao hơn. Cập nhật định kỳ với pg_cron extention (asynchronous) Dùng pg_cron trong database để lập lịch công việc để định kỳ lấy bản ghi cần xử lý, sinh embeddings theo lô và cập nhật. Không sử dụng trigger, nên không ảnh hưởng giao dịch ghi tài liệu ban đầu. Ưu điểm: kiến trúc đơn giản, ít phụ thuộc bên ngoài. Nhược điểm: embedding chậm trễ, overhead batch, ảnh hưởng tải database khi chạy cron. Các yếu tố thiết kế cần cân nhắc Khi lựa chọn cách triển khai cho môi trường sản xuất, bạn nên cân nhắc:\nGiới hạn tốc độ API của Bedrock các cuộc gọi thường xuyên có thể cần throttling hoặc batching. Giới hạn token trong mô hình embedding văn bản dài có thể cần chia nhỏ. Chi phí phụ thuộc vào giao dịch Lambda API, dịch vụ AWS sử dụng. Độ trễ với tính đồng bộ mỗi cách có đánh đổi riêng. Thao tác ghi vào database các cách đồng bộ có thể làm giảm hiệu năng khi tải cao. Xử lý lỗi kiến trúc bất đồng bộ hoặc có hàng đợi dễ hỗ trợ retry hơn. Bảo trì chỉ mục các chỉ số vector có thể xuống hiệu năng theo thời gian, cần tối ưu định kỳ. Cây quyết định Tác giả cung cấp sơ đồ quyết định để giúp bạn chọn chiến lược tự động embedding dựa trên nhu cầu ứng dụng (độ trễ, tính đồng bộ, độ phức tạp). Bắt đầu từ các cách đơn giản (ví dụ: cách 1 hoặc 5) rồi mở rộng khi nhu cầu tăng lên.\nHọ cũng lưu ý rằng cần bảo trì chỉ mục vector — tuỳ loại chỉ mục, việc bảo trì định kỳ cần thiết để giữ hiệu năng và độ nhớ lại trong tìm kiếm ngữ nghĩa.\nBạn có thể xem mã đầy đủ, scripts triển khai và ví dụ trong kho GitHub được liên kết trong bài viết.\nDọn dẹp Để tránh chi phí không cần thiết, tác giả khuyến nghị:\nXóa các stack CloudFormation đã triển khai cho demo Xóa các tài nguyên AWS bổ sung bạn đã tạo trong quá trình thử nghiệm Kết luận Tự động sinh embedding trong Aurora PostgreSQL giúp cho các tính năng AI như tìm kiếm ngữ nghĩa, gợi ý, truy hồi dữ liệu luôn được cập nhật khi dữ liệu thay đổi. Bằng cách giữ embeddings đồng bộ với dữ liệu, bạn đảm bảo tính liên quan và độ chính xác cho các ứng dụng AI.\nTrong bài viết, nhiều cách từ triggers, cron, hàng đợi đến giải pháp batch đều được trình bày với đánh đổi về độ trễ, khả năng mở rộng, tính đồng bộ và độ phức tạp vận hành. Lựa chọn tối ưu phụ thuộc vào nhu cầu ứng dụng của bạn — chấp nhận độ trễ, lượng ghi cao hay chi phí vận hành.\nBạn có thể vào kho GitHub trong bài viết để xem giải pháp đầy đủ và mã nguồn. Các tác giả rất hoan nghênh đóng góp hoặc phản hồi qua issues hoặc pull requests.\nTác Giả Andrea Filippo La Scola Andrea là Kiến trúc sư Giải pháp Đối tác (Partner Solutions Architect) tại AWS, chuyên về phân tích dữ liệu và kiến trúc serverless. Anh hỗ trợ các đối tác và khách hàng của AWS tại Ý trong việc thiết kế các giải pháp sáng tạo dựa trên các dịch vụ của AWS. Domenico di Salvia Domenico là Kiến trúc sư Giải pháp Chuyên gia về Cơ sở dữ liệu Cấp cao (Senior Database Specialist Solutions Architect) tại AWS. Trong vai trò này, Domenico làm việc với các khách hàng ở khu vực EMEA (Châu Âu, Trung Đông và Châu Phi), cung cấp hướng dẫn và hỗ trợ kỹ thuật cho các dự án cơ sở dữ liệu. Anh giúp họ nâng cao giá trị của giải pháp khi sử dụng hoặc di chuyển lên AWS, bằng cách thiết kế các kiến trúc cơ sở dữ liệu trong đám mây AWS có khả năng mở rộng, bảo mật, hiệu suất cao, bền vững, tiết kiệm chi phí và đáng tin cậy. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Nhóm các bảng cơ sở dữ liệu trong tác vụ AWS Database Migration Service (DMS) cho nguồn là PostgreSQL bởi Manojit Saha Sardar và Chirantan Pandya | vào ngày 05 tháng 9 năm 2025| trong Amazon Aurora, AWS Database Migration Service, Expert (400), PostgreSQL compatible, RDS for PostgreSQL, Technical How-to | Permalink\nTrong các dự án di chuyển dữ liệu lớn sử dụng AWS DMS (Database Migration Service), việc nhóm các bảng nguồn vào các tác vụ (tasks) một cách hợp lý là rất quan trọng để đảm bảo hiệu năng tốt và tránh độ trễ trong giai đoạn full load hoặc CDC. Trong bài viết này, các tác giả hướng dẫn cách phân tích cơ sở dữ liệu PostgreSQL nguồn để xác định kích thước task tối ưu và cách nhóm bảng, giúp bạn lên kế hoạch di chuyển dữ liệu sao cho giảm thiểu độ trễ và tối đa hóa thông lượng.\nBối cảnh \u0026amp; động lực Khi di chuyển, có thể xảy ra tình huống một số nhiệm vụ bị chậm hoặc nghẽn do cách nhóm bảng không hợp lý — chẳng hạn gộp quá nhiều bảng nhỏ hoặc trộn bảng rất lớn với bảng nhỏ khác. Sự chậm trễ có thể phát sinh trong cả pha full load hoặc khi áp dụng thay đổi theo CDC do cạnh tranh tài nguyên, nghẽn I/O, hoặc phân bố tải không đều. Bằng cách phân tích đặc tính bảng và các chỉ số hệ thống, bạn có thể đưa ra lựa chọn sáng suốt về số lượng task DMS, cách gộp bảng, và bảng nào cần tách riêng.\nTổng quan giải pháp Cách tiếp cận kết hợp metadata từ database nguồn (catalog, view thống kê) cùng với thông tin phần cứng và tải hoạt động để:\nXác định số task DMS thích hợp\nPhân nhóm bảng vào các task sao cho cân bằng\nCô lập các bảng “đặc biệt” (ví dụ: rất lớn, chứa LOB) để tránh ảnh hưởng chéo\nLuồng công việc đề xuất:\nTạo control table trên database nguồn\nĐiền thông tin metadata (kích thước, partition, index, LOB, thống kê DML)\nGiám sát mức độ thay đổi / tăng trưởng hàng ngày\n4.Phân loại bảng theo bước / ưu tiên\nGộp bảng vào các nhóm cho mỗi task\nTriển khai di chuyển theo các nhóm đó\nPhương pháp này giúp giảm thiểu độ trễ và đưa ra ước tính về kích thước task chính xác hơn.\n*Sơ đồ sau minh họa kiến trúc giải pháp.\nYêu cầu tiên quyết Bạn cần:\nCó kiến thức về AWS DMS (Database Migration Service) Database PostgreSQL nguồn, và khả năng chạy các script SQL / PL/pgSQL để thu thập metadata Bước 1: Tạo bảng control Trên database nguồn PostgreSQL, tạo bảng (ví dụ TABLE_MAPPING) để chứa metadata của mỗi bảng ứng cử: CREATE TABLE TABLE_MAPPING ( OWNER VARCHAR(30), OBJECT_NAME VARCHAR(30), OBJECT_TYPE VARCHAR(30), SIZE_IN_MB NUMERIC(12,4), STEP INTEGER, IGNORE CHAR(3), PARTITIONED CHAR(3), PART_NUM INTEGER, SPECIAL_HANDLING CHAR(3), PK_PRESENT CHAR(3), UK_PRESENT CHAR(3), LOB_COLUMN INTEGER, GROUPNUM INTEGER, TOTAL_DML INTEGER );\nBảng này lưu một dòng cho mỗi bảng (hoặc mỗi phân vùng), chứa các chỉ số như kích thước, số phân vùng, có PK/UK hay không, số cột LOB, tổng số DML, v.v.\nBước 2: Điền bảng control Sử dụng catalog hệ thống PostgreSQL và các view thống kê (ví dụ pg_tables, pg_partitioned_table, pg_inherits, và các view thống kê) để thu thập:\nKích thước bảng, thông tin partitioning\nSố lượng index, có hay không có primary / unique key\nSố cột LOB\nSố lượng DML (insert / update / delete)\nThống kê phân vùng (min, max, trung bình kích thước)\nĐiều này giúp bạn có “snapshot” metadata + workload để suy xét khi nhóm bảng.\nBước 3: Giám sát mức độ thay đổi Theo dõi lượng hoạt động DML trên mỗi bảng theo thời gian. Điều này giúp xác định bảng nào “nóng” (thay đổi nhiều) và bảng nào ít thay đổi, từ đó cân nhắc khi nhóm.\nBước 4: Phân loại bảng / gán bước Dựa vào kích thước bảng, tần suất thay đổi, nhu cầu xử lý đặc biệt (LOB, thiếu PK), hoặc partitioning, gán step number hoặc mức ưu tiên cho từng bảng. Ví dụ:\nStep 1: bảng nhỏ, thay đổi thấp\nStep 2: bảng trung bình / thay đổi vừa phải\nStep N: bảng rất lớn hoặc thay đổi mạnh\nBạn cũng có thể đánh dấu IGNORE cho những bảng không muốn đưa vào task cụ thể, hoặc SPECIAL_HANDLING để tách riêng các bảng đặc biệt.\nBước 5: Gộp bảng vào các task Dùng bảng control và phân loại bước để nhóm các bảng sao cho:\nMỗi nhóm có tải cân bằng (kích thước, mức độ thay đổi) Bảng rất lớn (ví dụ \u0026gt; 2 TB) có thể được tách riêng Bảng chứa LOB hoặc thiếu PK nên được nhóm cẩn trọng hoặc tách riêng Các bảng thay đổi nhiều có thể được cách ly để tránh ảnh hưởng lẫn nhau Số lượng task không quá nhiều, phù hợp với công suất của replication instance Mục tiêu là giảm lag, giảm cạnh tranh tài nguyên và phân bố tải đồng đều giữa các task. Các yếu tố cần cân nhắc Khi nhóm và định kích thước task, hãy xem xét:\nKích thước đối tượng database: các bảng cực lớn nên cô lập hoặc xử lý riêng Partitioned vs non-partitioned: các bảng phân vùng có thể cho phép di chuyển song song từng phân vùng Có PK / unique index: DMS yêu cầu PK/UK để xử lý LOB hoặc tránh trùng lặp Sử dụng LOB: các cột LOB làm tăng độ phức tạp và chi phí sao chép — nên cô lập các bảng có LOB nặng Khối lượng thay đổi (CDC): bảng có thay đổi thường xuyên nên được nhóm để tránh nghẽn áp dụng thay đổi Parallelism \u0026amp; giới hạn tài nguyên: khả năng của replication instance (CPU, I/O), băng thông mạng, v.v. quyết định số task hiệu quả Kiến trúc mẫu \u0026amp; luồng công việc Bài viết có sơ đồ minh họa cách phân loại nguồn bảng, nhóm và áp dụng các task song song (không thể hiện ở đây). Nó cũng mô tả cách bảng control được duy trì trong quá trình di chuyển và dùng để theo dõi tiến độ, cũng như điều chỉnh nhóm khi cần.\nTóm tắt \u0026amp; khuyến nghị Bằng cách:\nPhân tích metadata một cách có hệ thống\nPhân loại và gộp bảng dựa trên đặc tính và workload\nCô lập bảng rủi ro cao (rất lớn, LOB, thiếu PK)\nCân bằng tải giữa các task\nBạn có thể giảm rủi ro trong di chuyển, dự đoán kích thước task tốt hơn và đạt được migration mượt mà, hiệu suất cao.\nTác Giả Manojit Saha Sardar Manojit là kỹ sư cơ sở dữ liệu cấp cao tại AWS và được công nhận là chuyên gia trong lĩnh vực AWS DMS, Amazon RDS và Amazon RDS for PostgreSQL. Trong vai trò của mình tại AWS, anh hợp tác với khách hàng để giải quyết các tình huống truyền dữ liệu khác nhau và hỗ trợ xử lý các thách thức liên quan đến Amazon RDS for Oracle và Amazon RDS for PostgreSQL. Chirantan Pandya Chirantan là kỹ sư cơ sở dữ liệu (AWS Countdown Premium) và chuyên gia về AWS DMS và Amazon RDS for PostgreSQL. Tại AWS, anh làm việc chặt chẽ với khách hàng để cung cấp hướng dẫn và hỗ trợ kỹ thuật cho các dự án di chuyển cơ sở dữ liệu, cũng như các dự án liên quan đến Amazon RDS for PostgreSQL và Oracle. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Cloud Day” Mục Đích Của Sự Kiện Giới thiệu xu hướng phát triển của AI tại Việt Nam và cơ hội kinh tế. Trình bày sự tiến hóa từ Generative AI đến Agentic AI. Giới thiệu các giải pháp của AWS như Amazon Bedrock, AgentCore, và SageMaker Unified Studio trong việc xây dựng, triển khai và vận hành AI agent. Danh Sách Diễn Giả Kien Nguyen - Solutions Architect Jun Kai Loke - AI/ML Specialist SA, AWS Tamelly Lim - Storage Specialist SA, AWS Binh Tran - Senior Solutions Architect, AWS Taiki Dang - Solutions Architect, AWS Michael Armentano - Principal WW GTM Specialist, AWS Nội Dung Nổi Bật Tác động của AI đến kinh tế Việt Nam AI có thể đóng góp 120–130 tỷ USD vào GDP Việt Nam vào năm 2040 (~25%). Thị trường AI trị giá 750 triệu USD, tăng trưởng 15–18%/năm. Việt Nam hiện có 765 startup AI, đứng thứ 2 ASEAN. Cơ hội lớn nhưng vẫn ở giai đoạn đầu, cần thêm hạ tầng, nhân tài và chính sách. Sự tiến hóa của AI → Agentic AI Generative AI Assistants → Generative AI Agents → Agentic AI Systems. Các hệ thống AI ngày càng ít phụ thuộc con người: Multi-agent systems: các agent phối hợp cùng nhau giải quyết tác vụ phức tạp. Mức độ tự động hóa tăng dần, giảm dần sự giám sát của con người: Ứng dụng của Agentic AI trong tổ chức Nâng cao năng suất làm việc, tự động hóa quy trình, thúc đẩy đổi mới và nghiên cứu. Dự đoán đến 2028, 33% ứng dụng doanh nghiệp sẽ tích hợp Agentic AI. 15% quyết định thường ngày trong doanh nghiệp sẽ được đưa ra tự động nhờ Agentic AI. Amazon Bedrock – Nền tảng AI toàn diện Cung cấp đa dạng mô hình từ nhiều hãng hàng đầu. Cho phép tùy chỉnh mô hình với dữ liệu riêng, đảm bảo bảo mật và kiểm soát chi phí. Tích hợp Responsible AI checks để đảm bảo an toàn. Hỗ trợ triển khai và vận hành agent nhanh chóng, an toàn và mở rộng dễ dàng. Amazon Bedrock AgentCore Môi trường triển khai và vận hành Agent bảo mật, có khả năng mở rộng cao. Hỗ trợ các framework: LangChain, CrewAI, LangGraph, Strands Agents. Quản lý short-term và long-term memory, có truy xuất ngữ nghĩa (semantic search). Tích hợp và khám phá tool dễ dàng. Hạ tầng dữ liệu và AI Giới thiệu Amazon SageMaker Unified Studio – trung tâm hợp nhất dữ liệu, phân tích và AI. Kết nối chặt chẽ với: Amazon Redshift, Athena, EMR, Glue – xử lý và lưu trữ dữ liệu. Amazon QuickSight – trực quan hóa dữ liệu. Amazon Bedrock – phát triển ứng dụng GenAI. Hỗ trợ tích hợp Zero-ETL giữa S3 data lake và Redshift data warehouse. Data Lakehouse Hỗ trợ nhiều loại lưu trữ: S3 Tables, Redshift Managed Storage. Kết nối các nguồn dữ liệu lớn: Aurora, DynamoDB, MSK, Kinesis, OpenSearch, Salesforce, SAP, Facebook Ads. Những Gì Học Được Về Tư Duy AI và Cloud Hiểu được xu hướng Agentic AI là giai đoạn tiếp theo của Generative AI và đang hot hiện tại. Agentic AI không chỉ là Chatbot mà là hệ thống có thể hành động và tự ra quyết định. Nắm bắt cách AWS Bedrock cung cấp nền tảng cho doanh nghiệp xây dựng hệ thống AI thông minh. Thấy rõ tầm quan trọng của AI agents trong tự động hóa doanh nghiệp và sáng tạo. Về Kiến Trúc Kỹ Thuật Hiểu mối liên kết giữa Bedrock – SageMaker – Redshift – S3 trong một hệ sinh thái AI hoàn chỉnh. Nắm được cách AWS xử lý memory, tool discovery, và observability cho AI agent. Ứng Dụng Vào Công Việc Áp dụng Amazon Berock cho dự án hiện tại: Sử dụng Amazon Titan Embeddings để tạo embedding Thử nghiệm Zero-ETL với Amazon Redshift để đơn giản hóa pipeline dữ liệu từ Aurora/DynamoDB. Đánh giá việc sử dụng Amazon Bedrock AgentCore để xây dựng các tác tử AI tự động hóa quy trình nghiệp vụ (thay vì chỉ dùng Lambda + Bedrock cơ bản). Trải nghiệm trong Sự Kiện Tham gia sự kiện Cloud Day là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn rõ ràng hơn về cách các doanh nghiệp đang ứng dụng AI để hiện đại hóa hệ thống và nâng cao năng suất.\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS chia sẻ sâu về Agentic AI và sự khác biệt so với Generative AI truyền thống. Qua các ví dụ thực tế của Amazon, tôi hiểu rõ hơn cách họ triển khai multi-agent systems để tối ưu quy trình doanh nghiệp. Trải nghiệm kỹ thuật thực tế Tìm hiểu cách hoạt động của Amazon Bedrock AgentCore, từ cách nó xử lý short/long-term memory đến quản lý công cụ tích hợp. Thấy rõ quy trình kết nối dữ liệu từ S3 – Redshift – SageMaker, và cách AI agents truy xuất dữ liệu để trả lời theo ngữ cảnh. Hiểu rõ mô hình Lakehouse và cơ chế Zero-ETL integration giữa data lake và data warehouse. Ứng dụng công cụ hiện đại Học cách triển khai Agentic AI nhanh chóng trên AWS Bedrock, với độ bảo mật và khả năng mở rộng cao. Bài học rút ra Agentic AI không chỉ là công nghệ mới, mà là bước tiến chiến lược để doanh nghiệp đạt tự động hóa cấp hệ thống. Hạ tầng AI hiện đại cần được thiết kế dựa trên dữ liệu và cloud-native architecture. AWS đang dẫn đầu trong việc cung cấp nền tảng toàn diện cho AI/ML, đặc biệt là Bedrock và SageMaker. Thấy rõ tầm quan trọng của AI agents trong tự động hóa doanh nghiệp và sáng tạo. Một Số Hình Ảnh Khi Tham Gia Sự Kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Generative AI with Amazon Bedrock” Mục Đích Của Sự Kiện Cung cấp kiến thức nền tảng về Generative AI và sự khác biệt so với Machine Learning truyền thống. Mô tả chi tiết về dịch vụ Amazon Bedrock và các mô hình nền tảng (Foundation Models). Hướng dẫn kỹ thuật về RAG (Retrieval Augmented Generation) để xây dựng ứng dụng AI thông minh, chính xác và tránh ảo giác. Giới thiệu hệ sinh thái các dịch vụ AI chuyên biệt của AWS. Danh Sách Diễn Giả Lam Tuan Kiet - Sr DevOps Engineer, FPT Software. Danh Hoang Hieu Nghi - AI Engineer, Renova Cloud. Dinh Le Hoang Anh - Cloud Engineer Trainee, First Cloud AI Journey. Nội Dung Nổi Bật Sự chuyển dịch: Traditional ML vs Foudation Models Traditional ML Models: Chuyên biệt cho từng tác vụ cụ thể (Specific tasks), cần dữ liệu được gán nhãn (Labeled data), quy trình Train/Deploy phức tạp cho từng mục đích. Foundation Models (FM): Được huấn luyện trên dữ liệu phi cấu trúc khổng lồ (Unlabeled data), có khả năng thích ứng cho nhiều tác vụ khác nhau như: Text generation, Summarization, Q\u0026amp;A, Chatbot. Hệ sinh thái AI trên AWS Amazon Bedrock: Nơi hội tụ các mô hình FM hàng đầu từ các đối tác của AWS(AI21 Labs, Anthropic, Cohere, Meta, Stability AI,\u0026hellip;) và mô hình của Amazon. AWS Specialized AI Services: Các dịch vụ AI của AWS có thể gọi là \u0026ldquo;mì ăn liền\u0026rdquo; được tối ưu cho tác vụ cụ thể mà không cần train mô hình: Amazon Rekognition: Phát hiện đối tượng, Nhận diện khuôn mặt, Nhận diện cảm xúc, Nhận diện cảm xúc, Nhận diện người nổi tiếng, phân tích video - 0.001$/ảnh với 1 triệu ảnh đầu tiên Amazon translate: Dịch thuật văn bản đa ngôn ngữ theo thời gian thực với độ chính xác cao và văn phong tự nhiên. Amazon Textract: Trích xuất thông tin có cấu trúc (bảng biểu, form mẫu) từ văn bản quét hoặc PDF. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản Amazon Polly: Chuyển đổi văn bản thành giọng nói. Amazon Comprehend: Phân tích cảm xúc văn bản, trích xuất từ khóa và phân loại chủ đề tự động. Amazon Kendra: Cho phép hỏi đáp bằng ngôn ngữ tự nhiên để tìm thông tin trong tài liệu nội bộ của doanh nghiệp. Amazon Lookout: Phát hiện các bất thường trong dây chuyền sản xuất hoặc máy móc công nghiệp để bảo trì dự đoán. Amazon Personalize: Xây dựng hệ thống gợi ý theo thời gian thực, sử dụng công nghệ máy học. Kỹ thuật Prompting: Chain of Thought (CoT) So sánh giữa Standard Prompting là hỏi thẳng kết quả và Chain-of-Thought Prompting. CoT hướng dẫn mô hình suy luận từng bước để giải quyết các bài toán logic phức tạp, giúp tăng độ chính xác đáng kể so với việc chỉ đưa ra đáp án cuối cùng. RAG (Retrieval Augmented Generation) – Trọng tâm kỹ thuật Vấn đề: Giải quyết hiện tượng \u0026ldquo;ảo giác\u0026rdquo; và thiếu kiến thức cập nhật của LLM. Giải pháp: Kết hợp khả năng truy xuất dữ liệu (Retrieval) từ Knowledge Base bên ngoài với khả năng tạo sinh (Generation) của LLM. Quy trình Data Ingestion (Nạp dữ liệu): Dữ liệu thô (New data) $\\rightarrow$ Chia nhỏ (Chunking). Đi qua Embeddings model (ví dụ: Amazon Titan Text Embeddings V2.0). Lưu trữ dưới dạng vector vào Vector Store (OpenSearch Serverless, Pinecone, Redis\u0026hellip;). RetrieveAndGenerate API: API quản lý toàn bộ quy trình từ nhận input người dùng $\\rightarrow$ tạo query embedding $\\rightarrow$ truy xuất dữ liệu $\\rightarrow$ bổ sung ngữ cảnh (augment prompt) $\\rightarrow$ sinh câu trả lời. Những Gì Học Được Về Tư Duy AI và Cloud Hiểu rõ khi nào nên dùng Specialized AI Services cho bài toán nhanh, cụ thể và khi nào dùng Bedrock/GenAI cho bài toán sáng tạo, phức tạp. Nắm vững tư duy thiết kế hệ thống RAG: Không chỉ là gọi API của LLM, mà là bài toán quản lý dữ liệu và vector hóa để cung cấp ngữ cảnh đúng cho AI tạo phản hồi chuẩn hơn. Về Kiến Trúc Kỹ Thuật Kỹ thuật Chain of Thought là chìa khóa để tối ưu hóa kết quả đầu ra của mô hình mà không cần fine-tuning. Hiểu sâu về vai trò của Amazon Titan Embeddings V2.0 trong việc chuyển đổi văn bản đa ngôn ngữ thành vector (hỗ trợ 100+ ngôn ngữ, vector size linh hoạt 256/512/1024). Ứng Dụng Vào Công Việc Áp dụng Amazon Berock cho dự án hiện tại: Amazon Rekognition: nhận diện món ăn từ ảnh để tự động điền thông tin calo, Amazon Comprehend: phân tích text để chuẩn hóa món ăn lấy và ghi dữ liệu calo. Áp dụng thử kĩ thuật RAG cho dự án hiện tại. Sử dụng Bedrock Agents để điều phối các tác vụ như truy vấn món ăn từ vector store, tính toán mục tiêu calo và xây dựng thực đơn từng ngày. Trải nghiệm trong Sự Kiện Tham gia buổi workshop Generative AI with Amazon Bedrock mang lại cái nhìn rất thực tế về cách xây dựng ứng dụng AI hiện đại, đi từ lý thuyết nền tảng đến triển khai thực tế.\nKiến thức thực chiến từ chuyên gia Các diễn giả đã giải thích khá rõ ràng luồng đi của dữ liệu trong một hệ thống RAG, giúp tôi hình dung được \u0026ldquo;hộp đen\u0026rdquo; phía sau các ứng dụng Chatbot hiện nay đang sử dụng. Việc phân tích rõ ràng giữa Traditional ML và Generative AI giúp tôi định hình lại chiến lược chọn công nghệ cho các dự án sắp tới. Trải nghiệm công nghệ Ấn tượng với RetrieveAndGenerate API của Bedrock vì nó giúp giảm bớt rất nhiều công sức code thủ công cho phần kết nối giữa Vector Store và LLM. Thấy được sức mạnh của Amazon Titan Embedding trong việc hỗ trợ đa ngôn ngữ, rất phù hợp cho các ứng dụng tại thị trường Việt Nam. Bài học rút ra RAG là tiêu chuẩn mới: Để AI ứng dụng được trong doanh nghiệp, RAG là bắt buộc để đảm bảo tính chính xác và bảo mật dữ liệu. Hệ sinh thái toàn diện: AWS cung cấp đầy đủ từ tầng hạ tầng (Vector Store) đến tầng mô hình (Bedrock) và tầng ứng dụng (Agents), giúp việc triển khai nhanh chóng hơn rất nhiều. Một Số Hình Ảnh Khi Tham Gia Sự Kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về Amazon Bedrock Amazon Bedrock là dịch vụ machine learning được quản lý hoàn toàn của AWS, cung cấp khả năng truy cập đến các mô hình nền tảng (Foundation Models) hàng đầu từ Anthropic (Claude), Amazon (Titan), Meta (Llama), và nhiều nhà cung cấp khác thông qua API đơn giản.\nAnthropic Claude - Claude 2, Claude 3 Meta Llama - Llama 2 Amazon Titan - Titan Text AI21 Labs - Jurassic-2 Tổng quan về workshop Trong workshop này, bạn sẽ học cách:\nKhám phá Bedrock Console\nTạo AI Agent với AWS Lambda\nExpose API cho ứng dụng bên ngoài\nKiểm thử với giao diện web đơn giản\nNguồn hình ảnh\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.3-vpc-to-internet/5.3.1-create-gwe/",
	"title": "Khám phá bedrock",
	"tags": [],
	"description": "",
	"content": " Search Amazon Bedrock pricing Mình xem xét giá cả từng loại model và miền xem có phù hợp với nhu cầu của mình hay không Mở AWS Console → Amazon Bedrock Chọn model catalog , chọn 1 model bất kỳ để test sao cho phù hợp với mục đích và giá tiền của bạn Mình ở đây sẽ chọn Amazon Nova 2 lite vì nó rẻ ($0.0003/per 1000 tokens) Chọn vào Open in Playground Thử prompt và cho kết quả Kết quả model đưa ra là khá ấn tượng . "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Chào mừng đến với hội thảo của Bảo Nguyên\nChào mừng đến với nhật ký công việc của tôi – một hành trình cá nhân cùng AWS “Hành Trình Lên Mây Đầu Tiên”.\nKhông gian này ghi lại hành trình 12 tuần học hỏi, thử nghiệm và xây dựng của tôi với **Amazon Web Services.\nTừ những bước đầu tiên khám phá kiến ​​thức cơ bản cho đến khi dấn thân vào các dự án thực tế, nhật ký công việc này phản ánh cách tôi bắt đầu hành trình “lên mây”. Nó không chỉ là một bản ghi chép về các nhiệm vụ và thành tựu, mà còn là câu chuyện về sự trưởng thành, thử thách và những khám phá trên suốt chặng đường.\nĐi thôi!\nTuần 1: Làm quen với AWS, thiết lập tài khoản và quản lý chi phí\nTuần 2: Xây dựng hạ tầng mạng và bảo mật với Amazon VPC\nTuần 3: Quản trị máy chủ ảo EC2, Auto Scaling và giám sát hệ thống\nTuần 4: Lưu trữ dữ liệu và giải pháp sao lưu, phục hồi thảm họa trên AWS\nTuần 5: Bảo mật hệ thống, quản lý danh tính (IAM) và tuân thủ\nTuần 6: Triển khai và vận hành cơ sở dữ liệu (RDS, DynamoDB, ElastiCache)\nTuần 7: Kiến trúc Serverless và mô hình Event-Driven trên AWS\nTuần 8: Tự động hóa hạ tầng (IaC) và quản lý cấu hình hệ thống\nTuần 9: Phân tích dữ liệu và hệ sinh thái AI/Machine Learning trên AWS\nTuần 10: Giám sát, kiểm toán hệ thống và triển khai ứng dụng với AWS Amplify\nTuần 11: Quy trình CI/CD, triển khai ứng dụng với Elastic Beanstalk và tích hợp dịch vụ AI\nTuần 12: Tổng hợp kiến thức, thiết kế hệ thống và chuẩn bị kỹ thuật cho Capstone Project\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Tạo Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Knowledge Base là gì ? Knowledge Base (Cơ sở kiến thức) là \u0026ldquo;bộ nhớ riêng\u0026rdquo; để Agent truy cập thông tin chuyên biệt của bạn, mà mô hình AI gốc không biết.\nỞ trang giao diện của Aws Bedrock mình chọn phía trái Knowledge Base Khi bạn cấu hình xong rồi , đợi khoảng 5 phút để nó khởi tạo . Như thế này đã tạo xong Knowledge base. Lưu ý bạn nên cấu hình theo nhu cầu và nên cấp quyền cần thiết cho nó\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách tạo và quản lý chi phi với tài khoản AWS. Cách dùng console \u0026amp; CLI để tương tác và quản lý các dịch vụ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 08/09/2025 08/09/2025 3 - Tìm hiểu AWS và các loại dịch vụ cơ bản + Compute (EC2) + Storage (S3) + Networking (VPC) + Database (RDS) 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Quản lý danh tính và quyền truy cập + Cài AWS CLI \u0026amp; cấu hình + Sử dụng AWS CLI với các thao tác cơ bản 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu cách quản lý chi phí hiệu quả với AWS budget + Budget + Cost Budget, + Usage Budget + Reservation (RI) Budget + Saving plans Budget - Thực hành: + Tạo Cost Budget + Tạo Usage Budget + Tạo RI Budget + Tạo Savings Plans Budget + Dọn Dẹp Tài Nguyên 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về dịch vụ AWS Support - Các gói hỗ trợ của AWS + Gói Basic, Developer, Business và Enterprise - Các loại yêu cầu hỗ trợ + Hỗ trợ Tài khoản và Thanh toán + Hỗ trợ nâng hạn mức dịch vụ + Hỗ trợ Kỹ thuật - Thực hành: + Chọn gói hỗ trợ Basic + Tạo yêu cầu hỗ trợ 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute: Cung cấp tài nguyên xử lý cho ứng dụng như máy ảo, container,\u0026hellip; Storage: Dùng để lưu trữ dữ liệu, sao lưu và phục hồi Networking: Quản lý hạ tầng mạng, bảo mật, và kết nối giữa các tài nguyên AWS. Database: Cung cấp dịch vụ quản lý cơ sở dữ liệu quan hệ và phi quan hệ. Đã tạo cấu hình và định danh AWS Free Tier account thành công.\nĐã biết tạo và quản lý Group user, User.\nBiết cách đăng nhập bằng IAM và các user trong cùng một group sẽ được dùng chung quyền được cấp.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Tạo và xóa S3 Bucket Sử dụng SNS amazon Tạo IAM group, user và thêm user Tạo và xóa acess key Tạo và cấu hình cơ bản VPS Chạy và chấm dứt EC2 Nắm được cách quản lý và giám sát chi phí trên AWS thông qua các công cụ:\nTạo và cấu hình các gói Budget (Cost, Usage, RI, Savings Plan). Biết cách dọn dẹp tài nguyên để quản lý chi phí hiệu quả. Hiểu về các gói hỗ trợ của AWS và biết cách tạo yêu cầu hỗ trợ từ trung tâm hỗ trợ.\nBasic: Miễn phí, hỗ trợ các vấn đề liên quan đến tài khoản và thanh toán từ trung tâm trợ giúp Developer: 29 USD/tháng, tư vấn kiến trúc cơ bản, và hỗ trợ kỹ thuật không giới hạn được tạo từ tài khoản gốc (root user) Business:100 USD/tháng, lựa chọn phổ biến cho các doanh nghiệp vừa và nhỏ với các hỗ trợ như: Chỉ dẫn theo Use-case cụ thể, Hỗ trợ sử dụng AWS Support API, không giới hạn các yêu cầu hỗ trợ được tạo bởi tất cả các IAM User,\u0026hellip; Enterprise: 15.000 USD/tháng, cho doanh nghiệp quy mô lớn được đảm bảo các tiêu chí bảo mẩ tiêu chuẩn và nghiêm ngặt nhất với các dịch vụ bảo mật như: về kiến trúc phần mềm, hạ tầng, hỗ trợ toàn diện về chiến lược và tối ưu chi phí, được ưu tiên chăm sóc đặc biệt các yêu cấu hỗ trợ,\u0026hellip; Làm quen với giao diện AWS Console và sử dụng tốt các thao tác cơ bản qua cả Console và CLI.\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Thiết kế và triển khai VPC theo tiêu chuẩn AWS Well-Architected Framework Cấu hình các thành phần bảo mật mạng quan trọng Thiết lập kết nối an toàn giữa môi trường on-premise và AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Amazon Virtual Private Cloud (Amazon VPC), Kiến trúc và Phạm vi + AWS Region + Availability Zones (AZ) + Classless Inter-Domain Routing (CIDR) - Tìm hiểu về các thành phần cơ bản của Amazon VPC + Subnet + Route Table + Internet Gateway + NAT Gateway - Tìm hiểu về tường lửa trong VPC + Security Group + Network ACLs + Cách dùng Resource Map - Thực hành: + Tạo VPC + Tạo Subnet + Tạo Internet gateway + Tạo Route Table + Tạo Security Group + Kích hoạt VPC Flow Logs 15/09/2025 15/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu EC2 cơ bản + Instance types + AMI + Key pair + Thiết lập Network - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP - Tìm hiểu VPC Reachability Analyzer - Tìm hiểu AWS Systems Manager Session Manager và Amazon CloudWatch 16/09/2025 16/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Thực hành: Triển khai Amazon EC2 với multi-AZ, tạo NAT Gateways và Amazon CloudWatch cho VPC + Tạo máy chủ EC2 Public và Private Subnet + Kết nối SSH + Tạo và triển khai NAT Gateway + Sử dụng Reachability Analyzer + Tạo EC2 Instance Connect Endpoint + Sử dụng Session Manager + Triển khai CloudWatch Monitoring cho Tài nguyên VPC + Dọn dẹp tài nguyên: Terminate các EC2 Instance, Xóa NAT Gateway và Elastic IP Address, Xóa VPC Endpoints 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu AWS Site-to-Site VPN + AWS Site-to-Site VPN + Virtual Private Gateway + Customer Gateway + AWS VPN Tunnel - Tìm hiểu Transit Gateway - Tìm hiểu về VPC Peering 18/09/2025 18/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành:: + Cấu hình Site to Site VPN: Tạo môi trường VPN và cấu hình kết nối VPN + Thiết lập VPC Peering + Thiết lập Transit Gateway 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Tạo và cấu hình thành công VPC theo chuẩn AWS Well-Architected Framework:\nVPC chính với CIDR IP (10.0.0.0/16) Tạo 2 Subnet: Public và Private nằm ở hai Availability Zone khác nhau (multi-AZ). Route Table, Internet Gateway, và NAT Gateway được cấu hình đầy đủ để đảm bảo các EC2 trong Private Subnet vẫn có thể truy cập Internet an toàn. Kích hoạt VPC Flow Logs và theo dõi lưu lượng mạng trên CloudWatch Logs. Biết triển khai và quản lý EC2:\nKhởi tạo EC2 instance trong Public và Private Subnet, gán Elastic IP cho máy chủ Public. Truy cập EC2 qua SSH, Instance Connect, và Session Manager (không cần Public IP). Biết giám sát hoạt động EC2 thông qua Amazon CloudWatch (metric CPU, network, status check). Cấu hình được Security Group và Network ACLs để bảo mật\nSecurity Group – bảo vệ cấp instance. Network ACL – bảo vệ cấp subnet. Biết được CloudWatch Alarm để cảnh báo khi EC2 có lưu lượng hoặc CPU bất thường.\nNắm được và thực hành cấu hình AWS Site-to-Site VPN để kết nối an toàn giữa AWS và on-premises:\nTạo Virtual Private Gateway (VGW) gắn với VPC. Tạo Customer Gateway (CGW) mô phỏng on-premise environment. Thiết lập IPSec Tunnel hoạt động ổn định giữa AWS và CGW. Thực hành VPC Peering để kết nối giữa hai VPC riêng biệt trong cùng Region.\nTìm hiểu và thiết lập thử nghiệm AWS Transit Gateway.\nHiểu và áp dụng được AWS Systems Manager trong quản lý hạ tầng không cần SSH trực tiếp.\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Hiểu dịch vụ máy chủ ảo cốt lõi (Amazon EC2) và các thành phần quan trọng trong AWS. Hiểu rõ kiến trúc, cơ chế hoạt động và cách quản lý các dịch vụ máy chủ ảo trong AWS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Amazon Elastic Compute Cloud (EC2): + Instance type + AMI, Backup,keypair + Elastic block store + Instance store + User data + Meta data + EC2 auto scaling + EFS/FSx - Lightsail MGN 22/09/2025 22/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành: + Tạo và kết nối máy chủ EC2 trên Window và linux + Tạo Snapshor (Backup) EC2 + Cài đặt ứng dụng trên EC2 + Sử dụng Tag và Resource group để quản lý tài nguyên + Giới hạn sử dụng tài nguyên bằng dịch vụ IAM + Dọn dẹp tài nguyên 23/09/2025 23/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Amazon CloudWatch + Metrics + Logs + Alarms + Dashboard - Thực hành: + Cấu hình CloudWatch Metrics trên EC2 + Phân tích CloudWatch Logs từ các ứng dụng trên EC2 Instances và tạo Metrics Filters + Thiết lập CloudWatch Alarms để nhận thông báo + Xây dựng CloudWatch Dashboard để tổng hợp trạng thái EC2 + Dọn dẹp tài nguyên 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 auto scaling + Auto scaling group br\u0026gt; + Các loại Scaling: manual, scheduled, dynamic br\u0026gt; + Launch Template br\u0026gt; + Elastic Load Balancer - Thực hành + Tạo Launch Template cho EC2 + Tạo Target Group + Tạo Load Balancer + Tạo Auto Scaling Group để mở rộng linh hoạt + Kiểm tra kết quả của các cơ chế scaling + Dọn dẹp tài nguyên 25/09/2025 25/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu Amazon Lightsail + Lightsail Database + Wordpress Instance + Prestashop E-Commerce Instance + Akaunting Instance + Akaunting Instance - Thực hành: + Triển khai các loại instance và database: Wordpress Instance, Prestashop E-Commerce Instance và Akaunting Instance + Sử dụng Lightsail Loadbalancer + Tạo Snapshot để backup và khôi phục + Dịch chuyển sang instance lớn hơn + Dọn dẹp tài nguyên 26/09/2025 26/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 3: Nắm được kiến trúc và cơ chế hoạt động của Amazon EC2, phân biệt được các loại Instance Type (General Purpose, Compute Optimized, Memory Optimized, Storage Optimized).\nHiểu cách sử dụng Amazon Machine Image (AMI), Key Pair, Elastic Block Store (EBS), và Instance Store để cấu hình và quản lý máy chủ.\nBiết cách khai thác User Data và Meta Data để tự động hóa cấu hình khi khởi tạo EC2 Instance.\nHiểu và thực hành với EFS/FSx trong việc lưu trữ và chia sẻ dữ liệu giữa các máy chủ.\nTạo và kết nối thành công máy chủ EC2 trên cả Windows và Linux.\nTạo và khôi phục Snapshot (Backup) của EC2.\nCài đặt ứng dụng web cơ bản trên EC2 instance.\nSử dụng Tag và Resource Group để phân loại, quản lý tài nguyên hiệu quả.\nCấu hình IAM để giới hạn quyền truy cập và kiểm soát sử dụng tài nguyên.\nHiểu rõ các thành phần của Amazon CloudWatch: Metrics, Logs, Alarms, và Dashboard.\nCấu hình CloudWatch Metrics cho EC2 và tạo Metrics Filters từ log ứng dụng.\nThiết lập CloudWatch Alarm để nhận cảnh báo khi CPU hoặc lưu lượng mạng vượt ngưỡng.\nXây dựng CloudWatch Dashboard để tổng hợp và theo dõi trạng thái hệ thống EC2.\nHiểu rõ cơ chế hoạt động của EC2 Auto Scaling và các loại Scaling:\nManual: tự điều chỉnh số lượng EC2 instance thủ công khi cần thay đổi tài nguyên. Schedual: Tự động thay đổi số lượng instance theo lịch định sẵn, phù hợp với tải mà dự đoán được để tiết kiệm chi phí. Dynamic: Tự động mở rộng hoặc thu hẹp tài nguyên dựa trên các chỉ số CloudWatch như CPU hoặc lưu lượng mạng. Biết thiết lập và kiểm tra Auto Scaling Group hoạt động tự động khi tải tăng hoặc giảm.\nTìm hiểu và triển khai thành công các loại Lightsail Instance:\nWordPress Instance: website CMS cơ bản. PrestaShop Instance: nền tảng thương mại điện tử. Akaunting Instance: hệ thống quản lý tài chính kế toán. Sử dụng Lightsail Database để lưu trữ dữ liệu ứng dụng và Lightsail Load Balancer để phân phối tải và tăng độ sẵn sàng.\nBiết tạo Snapshot để backup dữ liệu và nâng cấp instance sang cấu hình lớn hơn\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Hiểu và ứng dụng các dịch vụ lưu trữ dữ liệu trên AWS như S3, Storage Gateway, và Snow Family. Nắm vững các cơ chế sao lưu và khôi phục dữ liệu với AWS Backup và Disaster Recovery on AWS. Biết cách triển khai giải pháp lưu trữ an toàn, mở rộng và đảm bảo tính sẵn sàng cao cho hệ thống ứng dụng. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Amazon Simple Storage Service (Amazon S3) + S3 Bucket + S3 Object + Access Point + Các lớp lưu trữ: Standard, Standard-IA, Intelligent-Tiering, Glacier + S3 Static Website \u0026amp; CORS + Control Access + Endpoint \u0026amp; Versioning + Object Key \u0026amp; Performance + Glacier: Expedited, Standard, Bulk - Thực hành: + Tạo S3 Bucket + Upload dữ liệu lên S3 + Host static wedsite trên S3: bật tính năng static wedsite, Cấu hình Block Public Access và public object + Kiểm tra wedsite + Tăng tốc wedsite với Cloufront + Di chuyển Object và sao chép S3 Object sang region khác + Dọn dẹp tài nguyên 29/09/2025 29/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu cách sử dụng AWS Backup để tạo ra một kế hoạch sao lưu cho các tài nguyên đang hoạt động trên AWS + Hạ tầng của AWS Backup + Backup Plan + AWS SNS (Simple Notification Service) - Thực hành: + Tạo S3 Bucket và triển khai hạ tầng AWS Backup + Tạo Backup Plan + Thiết lập Nofication + Kiểm tra hoạt động + Dọn dẹp tài nguyên 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Snow Family: + Snowball + Snowball Edge + Snowmobile - Tìm hiểu Storage Gateway + Cổng kết nối tập tin (File Gateway) + Cổng kết nối ổ đĩa (Volume Gateway) + Cổng kết nối băng từ (Tape Gateway) - Tìm hiểu Disaster Recovery: Recovery Time Object RTO và Recovery Point Object RPO + Sao lưu và khôi phụ + Pilot Light (Active-Standby) + Low Capacity (Active-Active) + Full Capacity (Active-Active) - Thực hành: + Tạo Storage Gateway + Tạo File Shares + Kết nối File shares ở máy On-premise + Dọn dẹp tài nguyên 01/10/2025 01/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu về AWS Import / Export - Thực hành: + Chuẩn bị máy ảo trên VMware Workstation + Import máy ảo vào AWS: Export máy ảo từ môi trường on-premises, Upload máy ảo lên AWS, Import máy ảo vào AWS, Khởi chạy EC2 instance từ AMI đã import + Export EC2 Instance từ AWS: Cấu hình ACL cho S3 bucket, Export máy ảo từ EC2 Instance, Export máy ảo từ AMI + Dọn dẹp tài nguyên 02/10/2025 02/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về Amazon FSx - Thực hàng: + Tạo môi trường thực hành + Tạo một SSD Multi-AZ file system + Tạo một HDD Multi-AZ file system + Tạo file shares mới + Kiểm tra hiệu năng + Giám sát hiệu năng + kích hoạt chống dữ liệu trùng lặp + Kích hoạt shadow copies + Quản lý Session người dùng và mở tệp + Kích hoạt hạn mức lưu trữ của người dùng + Kích hoạt chia sẻ liên tục + Scale quy mô thông qua năng suất + Scale dung lượng lưu trữ + Dọn dẹp tài nguyên. 03/10/2025 03/010/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 4: Hiểu cấu trúc và cách hoạt động của S3 Bucket, Object, Access Point, ACL/Policy, CORS, Versioning, Object Key, các lớp lưu trữ (Standard, IA, Intelligent-Tiering, Glacier).:\nTriển khai thành công:\nTạo bucket, upload object Host static website và cấu hình CloudFront tăng tốc Thiết lập truy cập công khai và kiểm soát truy cập Sao chép dữ liệu cross-region* Hiểu và thực hành các giải pháp lưu trữ on-premises tới AWS với Storage Gateway\nBiết được chi tiết về Snow Family và các use-case di chuyển dữ liệu lớn.\nHiểu và biết cách dùng Amazon FSx: tạo hệ thống Multi-AZ SSD/HDD, quản lý shares, shadow copy, chống trùng lặp, giám sát, mở rộng hiệu năng và dung lượng.\nNắm được các cơ chế sao lưu và khôi phục dữ liệu trên AWS (AWS Backup \u0026amp; DR)\nHiểu kiến trúc AWS Backup, Backup Vault, Backup Plan, và hoạt động lifecycle. Cấu hình thành công: Backup Plan, SNS, Notification, Tự động hóa sao lưu, Kiểm thử restore Hiểu chi tiết về Disaster Recovery: RTO: Thời gian tối đa để khổi phục hệ thống khi xảy ra sự cố RPO: Mức dữ liệu tối đa chấp nhận bị mất tính từ lức xảy ra sự cố Pilot Light: Warm Standby: Multi-Site Active-Active: Có khả năng triển khai giải pháp lưu trữ an toàn, mở rộng và đảm bảo tính sẵn sàng cao\nÁp dụng Versioning, Replication (S3) để tăng tính sẵn sàng. Sử dụng Multi-AZ FSx nhằm tạo kiến trúc lưu trữ chịu lỗi (High Availability). Sử dụng CloudFront giúp tối ưu hiệu năng phân phối tệp tĩnh. Hiểu các mô hình DR để thiết kế hệ thống có khả năng khôi phục nhanh khi xảy ra sự cố. Có khả năng scale dung lượng \u0026amp; throughput trên FSx. Nâng cao kỹ năng triển khai lưu trữ On-premises tới AWS và ngược lại\nBiết cách Import/Export máy ảo: Export VM từ VMware, Upload vào S3, Import thành AMI, Khởi chạy EC2, Xuất EC2 ngược lại thành VM Kết nối File Share từ Storage Gateway vào môi trường on-premise. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Hiểu các dịch vụ bảo mật trên AWS, các nguyên tắc bảo mật cốt lõi của AWS Quản lý danh tính, quyền truy cập và xác thực người dùng an toàn trên AWS. Bảo vệ và vận hành dữ liệu bằng các cơ chế mã hóa và quản lý dữ liệu. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về mô hình chia sẽ trách nhiệm + Trách nhiệm của \u0026ldquo;AWS\u0026rdquo; và của \u0026ldquo;Khách hàng\u0026rdquo; + Trách nhiệm bảo mật cuả từng loại hình dịch vụ - Tìm hiểu cơ bản Amazon identity and acess Management: + Root Account + AWS IAM + Chủ thể IAM + IAM User + IAM policy + IAM role + IAM permission boundary. 06/10/2025 06/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành: + Tạo IAM Group, IAM User, IAM Role và Assume Role + Tạo User quản trị EC2, User quản trị RDS và group quản trị + Cấu hình IAM Role Condition + Tạo IAM Role có quyền Admin + Tạo IAM User + Câu hình Switch role + Giới hạn theo IP hoặc thời gian + Giới hạn quyền của User + Tạo policy giới hạn quyền + Tạo IAM giới hạn + Kiểm tra User giới hạn + Dọn dẹp tài nguyên 07/10/2025 07/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu cách dùng Tag và Resource Groups: + Tag + AWS Resource Groups - Thực hành: + Sử dụng Tag bằng console: tạo EC2 với Tag, thêm hoặc xóa Tag và tạo tài nguyên theo Tag + Sử dụng Tag bằng CLI + Tạo Resource Group + Quản lý truy cập vào dịch vụ EC2 Resource Tag với AWS IAM + Tạo IAM User, IAM Policy và IAM Role + Chuyển Role + Kiểm tra IAM Policy: Truy cập vào AWS Region được/không cho phép, sử dụng Resource Tag với giá trị không thỏa mản điều kiện, chỉnh sửa Resource Tag trên EC2 và kiểm tra chính sách + Tạo IAM policy, IAM Role và kiểm tra IAM Role + Dọn dẹp tài nguyên. 08/10/2025 08/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu cơ bản Amazon Congnito: + User Pool + Identity Pool - Tìm hiểu về AWS Organization - Tìm hiểu về AWS identity center (SSO) - Tìm hiểu về AWS Key Management Service (KMS) - Tìm hiểu về AWS Security Hub - Thực hành: + Kích hoạt Securiy Hub + Điểm từng bộ tiêu chuẩn + Dọn dẹp tài nguyên. 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Sử dụng AWS SSO + Tạo AWS Account trong AWS Organizations, thiết lập organization Unit + Thiết lập AWS SSO và kiểm tra + Mã hóa với AWS KMS + Tạo Policy và Role + Tạo Group và User + Tạo Key Management Sevice + Tạo bucket và upload dữ liệu lên Amazon S3 + Tạo AWS CloudTrail để ghi nhật ký và Amazon Athena để truy xuất dữ liệu + Kiểm thử và chia sẽ dữ liệu mã hóa trên S3 + Dọn dẹp tài nguyên 10/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: Hiểu rõ hơn về mô hình bảo mật của AWS:\nTrách nhiệm bảo mật sẽ thay đổi theo từng loại dịch vụ, ví dụ: AWS sẽ chịu trách nhiệm bảo mật của cloud và quản lí hoàn toàn bởi AWS (hạ tầng, phần cứng\u0026hellip;) Khách hàng sẽ chịu trách nhiệm cấu hình bảo mật cho dữ liệu/ứng dụng của học (cấu hình dịch vụ, quyền truy cập, dữ liệu, mã hóa…) Biết được IAM, KMS có vai trò quan trọng trong bảo mật AWS Hiểu và biết cách sử dụng AWS IAM:\nnắm được các khái niệm: Root Account, IAM User, IAM Group, IAM Role, IAM Policy, Permission Boundary. Biết tạo và quản lý IAM cơ bản, phân quyền theo nguyên tắc least privilege, sử dụng Role để tăng bảo mật. Biết sử dụng Tag để kiểm soát và quản lý truy cập:\nBiết sử dụng Tag cho dịch vụ cơ bản qua Console và CLI Tạo được Resource Groups để gom tài nguyên theo thẻ Kiểm thử các trường hợp bị deny do sai Region, sai Tag hoặc không thỏa điều kiện IAM Policy. Hiểu được vai trò của AWS Cognito:\nUser Pool: quản lý tài khoản người dùng và quá trình đăng nhập Identity Pool: cấp AWS temporary credentials để ứng dụng truy cập các dịch vụ AWS. Biết cách sử dụng AWS Organizations và Identity Center:\nBiết tạo OU và nắm các nguyên tắc vận hành môi trường multi-account như: tách biệt môi trường, quản lý tập trung, áp chính sách bảo mật thống nhất. Biết thiết lập AWS SSO, tạo Permission Set và đăng nhập vào các tài khoản con từ một danh tính duy nhất. Biết dùng AWS KMS để mã hóa và bảo vệ dữ liệu\nBiết kích hoạt và sứ dụng AWS Security Hub để đánh giá các tiểu chuẩn bảo mật, hiểu lổi và cải thiện\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Biết các dịch vụ lưu trữ dữ liệu quan hệ (SQL) và phi quan hệ (NoSQL) của AWS tùy vào nhu cầu lưu trữ Biết cách triển khai, vận hành và tối ưu hóa cơ sở dữ liệu trên AWS Hiểu về Amazon ElastiCache để tăng tốc truy xuất dữ liệu Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Amazon RDS và Aurora + Các Engine: MySQL, PostgreSQL\u0026hellip; + Tính khả dụng Multi-AZ + Hiệu năng Read Replicas + Backup và khôi phục tự động 13/10/2025 13/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành: + Chuẩn bị môi trường để instance RDS: Tạo VPC, EC2, RDS Security Group, DB Subnet Group + Tạo EC2 Instance + Tạo RDS Database Instance trong Private Subnet kết nối với EC2 + Triển khai ứng dụng + Backup và khôi phục tự động + Dọn dẹp tài nguyên 14/10/2025 14/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Amazon DynamoDB: NoSQL + Các thành phần cốt lõi + Primary key và Soft key + Read/Write Capacity với On-demand hoặc Provisioned - Thực hành: Sử dụng AWS Console và Cloudshell để: + Tạo table + Ghi, đọc và cập nhật dữ liệu + Truy vấn dữ liệu + Tạo global secondary index + Truy vấn secondarry index 15/10/2025 15/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu các gói python của AWS ADK(for python) + Botocore + Boto3 - Thực hành: + Cấu hình AWS CLI với thư viện Boto3 + Sử dụng Python để phát triển với DynamoDB: Tạo Table, ghi, đọc, cập nhật, xóa dữ liệu, Tải dữ liệu mẫu, Truy vấn, quét dữ liệu và xóa dữ liệu table + Dọn dẹp tài nguyên. 16/10/2025 16/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu Amazon ElastiCache + ElastiCache for Redis: Clusters + ElastiCache nodes + ElastiCache for Redis shards - Thực hành: + Tạo IAM User Access Keys để cấu hình AWS CLI + Sử dụng AWS Console và CLI để tạo ElastiCache cluster + Dùng AWS SDK để ghi và đọc dữ liệu trên ElastiCache: + Tạo và kết nối với Clusters + Set and Get strings + Set and Get a hash with multiple items + Publish (write) and subscribe (read) + Write and read from a stream 17/10/2025 17/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 6: Hiểu biết về Cơ sở dữ liệu quan hệ Amazon RDS \u0026amp; Aurora\nNắm được kiến trúc RDS, các database engine (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, Aurora). Hiểu cơ chế Multi-AZ Deployment Biết cách tối ưu đọc bằng Read Replicas. Triển khai hệ thống RDS thực tế\nTự triển khai một kiến trúc gồm: VPC, Subnet Groups, Security Group, EC2 Bastion Host, RDS Private Instance. Kết nối EC2 với RDS thông qua security group. Triển khai ứng dụng kết nối đến RDS. Thực hiện backup/restore và dọn dẹp tài nguyên. Hiểu và sử dụng Amazon DynamoDB (NoSQL)\nHiểu các khái niệm cốt lõi: Tables, Items, Attributes, Partition key, Sort key RCU/WCU, On-demand vs Provisioned Global Secondary Index (GSI), Local Secondary Index (LSI) Biết cách tối ưu truy vấn nhờ thiết kế key đúng chuẩn. Thực hành các thao tác CRUD, Query, Scan, GSI Query. Sử dụng được AWS SDK for Python (Boto3)\nCấu hình AWS CLI \u0026amp; credentials để làm việc với Boto3. Tự viết code Python để: Tạo bảng DynamoDB Ghi / đọc / cập nhật / xóa dữ liệu Quét dữ liệu (Scan) và Query có điều kiện Xóa bảng và giải phóng tài nguyên Biết cấu trúc API của Boto3 và cách xử lý lỗi.\nHiểu và triển khai Amazon ElastiCache for Redis\nNắm kiến trúc ElastiCache: node, shard, cluster, primary/replica. Hiểu cluster mode enabled / disabled. Tạo ElastiCache Redis cluster bằng Console và CLI. Sử dụng AWS SDK để: Set/Get key-value Set/Get hash Publish/Subscribe Làm việc với Redis Stream Hiểu vai trò của caching trong tối ưu hóa ứng dụng. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Nắm được kiến trúc và cách hoạt động của mô hình Serverless với Lambda và API Gateway. Hiểu được cơ chế vận hành của AWS Lambda và hiểu cơ bản về kiến trúc Event-Driven Biết cách sử dụng sử dụng SQS và SNS với kiến trúc hợp lí Cấu hình API Gateway làm trigger Lambda + Lưu dữ liệu từ Lambda xuống DynamoDB\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về AWS Lambda + IAM Role cho Lambda + Lambda function - Tìm hiểu về Amazon API Gateway + Các method + CORS - Thực hành: + Tạo role cấp quyền tối thiểu cho Lambda để truy cập S3 và DynamoDB + Tạo Lambda function để xử lí file upload + Cấu hình API Gateway trigger Lambda + Lưu dữ liệu từ Lambda xuống DynamoDB 20/10/2025 20/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành: Tương tác giữa Lambda với S3 và DynamoDB + Tạo lambda function xử lý ảnh + Tạo S3 Bucket + Tạo IAM Policy cho lambda fuction và kiểm tra hoạt động + Tạo và quản lý bảng trong AWS DynamoDB + Tạo lambda fuction để ghi dữ liệu vào + Dọn dẹp tài nguyên 21/10/2025 21/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Thực hành: Host website tĩnh trên S3 + Tạo Bucket, bật enable, gán policy và tải thư mục frontend lên S3 + Tạo bảng DynamoDB, triển khai lambda function để ghi, đọc và xóa dữ liệu + Thiết lập API Geteway + Kiểm trai API với Postman + Kiểm tra API với front-end + Dọn dẹp tài nguyên 22/10/2025 22/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu kiến trúc Event-driven với Amazon SQS và SNS + SQS: queue\n+ SNS: Pub và Sub - Thực hành: + Tạo Queue và chủ đề SNS + Tạo API và Lambda function để tương tác với Queue và chủ đề SNS + Kiểm tra hoạt động với APIs + Dọn dẹp tài nguyên 23/10/2025 23/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu AWS Step Functions + Orchestrate microservices 24/10/2025 24/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Hiểu biết về Kiến trúc Serverless trên AWS\nNắm được kiến trúc và mô hình hoạt động của AWS Lambda, vòng đời thực thi và chi phí dựa trên thời gian chạy.\nHiểu rõ API Gateway hoạt động như một HTTP front-door cho Lambda, bao gồm:\nREST API, HTTP API: Các loại API trong API Gateway dùng để expose backend; REST API đầy đủ tính năng, HTTP API nhẹ và tối ưu chi phí. Methods: Định nghĩa hành động HTTP (GET/POST/PUT/DELETE) và liên kết đến Lambda hoặc backend khác. CORS: Cho phép front-end từ domain khác gọi API, cấu hình qua các header CORS. Integration request/response: Lớp chuyển đổi dữ liệu giữa API Gateway và backend, gồm mapping input và output. Hiểu cách thiết kế kiến trúc event-driven, luồng dữ liệu và ưu điểm so với mô hình truyền thống.\nTriển khai được Lambda – API Gateway – DynamoDB – S3\nTạo IAM Role với quyền tối thiểu (Least Privilege) cho Lambda truy cập S3 và DynamoDB. Tạo Lambda Function để: Xử lý file upload từ S3 Ghi, đọc, cập nhật dữ liệu DynamoDB Tạo API Gateway để trigger Lambda và xử lý request/response. Cấu hình static website hosting trên S3 và kết nối front-end với API Gateway. Tương tác giữa Lambda – S3 – DynamoDB\nTạo S3 bucket và bật event notifications cho Lambda.\nViết Lambda xử lý ảnh hoặc dữ liệu upload vào S3. Thao tác CRUD với DynamoDB từ Lambda. Tạo bảng DynamoDB, index (nếu cần) và xử lý dữ liệu nhiều dạng. Hiểu và triển khai hệ thống Event-driven với SNS \u0026amp; SQS\nNắm được mô hình: SNS (Publisher → Topic → Subscriber) SQS (Producer → Queue → Consumer) Tạo SNS topic và SQS queue, kết nối SNS → SQS (fan-out). Viết Lambda function để publish và consume message. Test luồng truyền thông qua API Gateway và Lambda. Tìm hiểu AWS Step Functions\nHiểu khái niệm orchestration so với choreography. Biết cách Step Functions điều phối nhiều Lambda/microservices qua State Machine. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Tự động hóa việc tạo tài nguyên bằng CloudFormation Quản lý cấu hình hệ thống Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu AWS CloudFormation, Cloud9 + Template: Json, Yaml + Stack + Drift Detection\n-Thực hành + Sử dụng Cloud9 để tạo CloudFormation template cơ bản 27/10/2025 27/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành: CloudFormation nâng cao: + Tạo Lambda Funtion + Tạo Stack + Kết nối EC2 instance + Ánh xạ và StackSets + Drift Detection + Dọn dẹp tài nguyên 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu AWS Systems Manager (SSM) + Patch Manager + Run Command + Session manager - Thực hành + Tạo EC2 instance, IAM Role và gán IAM Role + Cấu hình Patch Manager + Run Comman + Dọn dẹp tài nguyên 29/10/2025 29/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu AWS CDK Thực hành: AWS CDK với VS Code + Tạo EC2 instance public + Cấu hình môi trường VS Code để sử dụng AWS CDK + Tạo cụm ECS, Application và Kết hợp API Gateway với Application Load Balancer + Tạo Lambda function, API Gateway, S3 + Triển khai Stack và tải tập tin lên S3 + Tạo các Nested Stack với CDk và triển khai + Dọn dẹp tài nguyên. 30/10/2025 30/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: Session Manager: + Tạo EC2 instance private, public và IAM Role + Kết nối đến máy chủ Public + Tạo kết nối đến máy chủ EC2 Private + Cập nhật IAM Role để truy cập vào S3 + Tạo S3 Buckets và S3 Gateway VPC Endpoint + Theo dõi session logs với SSM Session Manager + Cấu hình Port Forwarding + Dọn dẹp tài nguyên. 31/10/2025 31/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Hiểu thực hành được cơ bản về CloudFormation\nHiểu kiến trúc CloudFormation, cách template hoạt động và vòng đời của Stack.\nPhân biệt được các thành phần chính:\nTemplate : định nghĩa tài nguyên (YAML/JSON) Parameters, Mappings, Resources, Outputs Stack: một nhóm tài nguyên triển khai từ template StackSets: triển khai stack cho nhiều tài khoản / nhiều region Drift Detection: kiểm tra sự khác biệt giữa tài nguyên thực tế và template Tạo được CloudFormation template cơ bản để triển khai tài nguyên (EC2, Lambda, Security Group…).\nTriển khai CloudFormation nâng cao\nTạo stack triển khai Lambda function và EC2. Biết cách sử dụng Mappings, Parameters, Outputs trong template. Sử dụng được StackSets để triển khai cho nhiều Region/AWS Account. Thực hành Drift Detection để phát hiện thay đổi so với template. Thực hành cơ bản được quy trình deploy – update – delete stack. Biết các sử dụng AWS Systems Manager (SSM)\nTạo EC2 và cấu hình IAM Role để kết nối với SSM.\nSử dụng Session Manager để kết nối EC2 mà không cần SSH/Keypair.\nThực hành:\nChạy lệnh từ xa với SSM Run Command Cấu hình và chạy Patch Manager để cập nhật OS Ghi logs truy cập EC2 vào S3 Thực hành Port Forwarding qua SSM Hiểu lợi ích bảo mật khi không mở port 22.\nBiết cách dùng Session Manager\nKết nối EC2 Public → EC2 Private thông qua Session Manager. Tạo và sử dụng S3 Gateway VPC Endpoint để EC2 private truy cập S3 mà không cần Internet. Theo dõi hoạt động trong Session Manager Logs. Dọn dẹp tài nguyên. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Làm quen với hệ sinh thái dữ liệu và Machine Learning trên AWS. Nắm được các tính năng chính trong hệ sinh AI của AWS hỗ trợ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu AWS Glue + Crawler - Tìm hiểu Amazon Athena - Tìm hiểu Amazon QuickSight - Tìm hiểu Amazon SageMaker 03/11/2025 03/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành: Phân tích dữ liệu: + Tạo IAM Role và IAM policy + Tạo S3 Bucket + Tạo Glue Crawler và kiểm tra dữ liệu + Tạo notebook với AWS Glue Studio + Phân tích với Athena và trực quan với QuickSight Dọn dẹp tài nguyên 04/11/2025 04/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Thực hành: Phân tích dữ liệu với Amazon SageMaker: + Tạo SageMaker Studio + Chuẩn bị dataset, phân tích dữ liệu và export dữ liệu tới S3 + Train và tinh chỉnh mô hình Machine learning + Triển khai và đánh giá hiệu suất mô hình + tinh chỉnh mô hình tự động + Dọn dẹp tài nguyên 05/11/2025 05/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu các Amazon Bedrock + Các Foundation model + Bedrock Agents + Knowledge Bases + Bedrock Inference Features 06/11/2025 06/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu các tính năng trong Pre-trained AI Services + Amazon Rekognition + Amazon translate + Amazon Textract + Amazon Transcribe + Amazon Polly + Amazon Comprehend + Amazon Kendra + Amazon Lookout + Amazon Personalize 07/11/2025 07/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu và biết cách xây dựng luồng xử lý dữ liệu Serverless:\nHiểu rmô hình Data Lake hiện đại trên AWS, Lấy S3 làm trung tâm lưu trữ AWS Glue: Glue Crawler trong việc tự động phát hiện schema từ dữ liệu thô (CSV/JSON trong S3) và tạo Metadata Table trong Glue Data Catalog, biến dữ liệu phi cấu trúc thành có cấu trúc để query. Amazon Athena: Thực hiện được truy vấn SQL trực tiếp trên dữ liệu nằm tại S3 mà không cần provision server hay load dữ liệu vào database truyền thống. Amazon QuickSight: Biết cách kết nối với Athena để trực quan hóa dữ liệu, tạo dashboard BI (Business Intelligence) để ra quyết định dựa trên dữ liệu. Hiểu quy trình phát triển Machine Learning trên Amazon SageMaker:\nMôi trường: SageMaker Studio Training: Hiểu cơ chế tách biệt tài nguyên: Notebook dùng để code, nhưng khi gọi fit(), SageMaker sẽ khởi tạo cụ Training Cluster riêng biệt, train xong tự tắt để tối ưu chi phí. Optimization: Biết cách sử dụng Automatic Model Tuning để tìm ra bộ tham số tốt nhất cho mô hình thay vì thử thủ công. Deployment: Triển khai mô hình đã train thành một Endpoint (REST API) để phục vụ dự đoán theo thời gian thực. Nắm bắt xu hướng Generative AI với Amazon Bedrock:\nHiểu được sự dịch chuyển từ việc \u0026ldquo;tự train model\u0026rdquo; sang việc \u0026ldquo;sử dụng Foundation Models (FM)\u0026rdquo; qua API .\nNắm được các thành phần cốt lõi để xây dựng ứng dụng LLM hiện đại: Knowledge Bases: Cơ chế RAG (Retrieval-Augmented Generation) để cung cấp dữ liệu riêng của doanh nghiệp cho AI. Agents: Giúp AI không chỉ \u0026ldquo;chat\u0026rdquo; mà còn thực hiện hành động (gọi API, tra cứu dữ liệu). Nắm được hệ sinh thái Pre-trained AI Services (AI không cần code):\nPhân loại được các nhóm dịch vụ để áp dụng đúng bài toán mà không cần build model từ đầu:\nVision: Rekognition (nhận diện ảnh/video). Speech/Audio: Transcribe (STT), Polly (TTS). NLP/Text: Translate, Comprehend (phân tích cảm xúc/entity), Textract (OCR tài liệu). Specialized: Personalize (gợi ý), Lookout (bảo trì dự đoán). "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "FoodMind Recommender Platform For Prompt-IPoG Giải pháp AWS Serverless hợp nhất cho việc theo dõi và gợi ý bữa ăn cá nhân hóa. 1. Tóm tắt điều hành FoodMind Recommender Platform là nền tảng web thông minh được thiết kế để trở thành một trợ lí ăn uống cá nhân thông minh. Nền tảng tự động tính toán calo mục tiêu (TDEE) dựa trên hồ sơ người dùng, sử dụng AWS Bedrock (AI Tạo sinh) để cho phép người dùng ghi log bữa ăn bằng ngôn ngữ tự nhiên (ví dụ: \u0026ldquo;tôi vừa ăn 1 bát phở bò\u0026rdquo;). Hệ thống cung cấp một tính năng gợi ý bữa ăn (Sáng/Trưa/Tối) thông minh, tự động \u0026ldquo;lọc\u0026rdquo; các món ăn dựa trên mục tiêu calo và các ràng buộc sức khỏe (ví dụ: \u0026ldquo;dị ứng\u0026rdquo;, \u0026ldquo;bệnh gout\u0026rdquo;) của người dùng.\nToàn bộ giải pháp được xây dựng trên kiến trúc serverless với giao diện sử dụng AWS Amplify (Frontend), API Gateway, AWS Lambda, và Amazon DynamoDB (Backend). Cho phép người dùng có thể nhận được gợi ý các món ăn trong ngày dựa trên lượng calo được tính toán theo người dùng sử dụng cần tiêu thụ trong ngày. Dữ liệu được lưu trữ và truy vấn qua Amazon DynamoDB, đảm bảo hiệu năng cao và mở rộng linh hoạt.\nGiải pháp tập trung vào sự kết hợp giữa AI và dữ liệu thực tế để hỗ trợ ra quyết định tìm món ăn linh hoạt và thiết kế dashboard để có thể xem quá trình theo dõi bữa ăn hàng ngày hiệu quả.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nNhiều người dùng gặp khó khăn trong việc quản lý chế độ ăn uống hàng ngày — không biết nên ăn bao nhiêu calo, món nào phù hợp với mục tiêu cá nhân cho mỗi ngày. Việc ghi chép thủ công và tra cứu dinh dưỡng gây mất thời gian, thiếu chính xác và không có tính cá nhân hóa.\nGiải pháp\nFoodMind Recommender Platform ứng dụng AI và AWS Cloud để tự động hóa toàn bộ quy trình theo dõi và gợi ý bữa ăn:\nTự động hóa Mục tiêu: Hệ thống tự động tính toán Calo Mục tiêu cho người dùng (dựa trên công thức Mifflin-St Jeor) ngay khi họ cập nhật hồ sơ. Tự động hóa Gợi ý: Hệ thống cung cấp API GET /recommendations sử dụng \u0026ldquo;logic nghiệp vụ\u0026rdquo; (do Lambda thực thi) để \u0026ldquo;lọc\u0026rdquo; (filter) kho dữ liệu món ăn, dựa trên Calo Mục tiêu (ví dụ: bữa trưa \u0026lt; 700 calo) và Luật cấm Bệnh lý (ví dụ: không chứa \u0026ldquo;thịt đỏ\u0026rdquo; cho bệnh gout). Tự động hóa Ghi log (AI Logging): Hệ thống cung cấp API POST /log-food sử dụng AWS Bedrock để \u0026ldquo;bóc tách\u0026rdquo; (parse) ngôn ngữ tự nhiên của người dùng. Hệ thống tự tra cứu calo và lưu vào nhật ký. Tự động hóa Học hỏi: Khi người dùng log một món ăn mới (ví dụ: \u0026ldquo;bún đậu mắm tôm\u0026rdquo;) mà hệ thống không biết, AWS Bedrock sẽ được dùng để \u0026ldquo;ước tính\u0026rdquo; calo và \u0026ldquo;tự động lưu\u0026rdquo; món mới này vào kho tri thức. Theo dõi Trực quan: Cung cấp dashboard (trên Amplify) hiển thị lịch sử ăn uống 7 ngày qua, giúp người dùng quan sát và theo dõi chế độ ăn uống cá nhân. Người dùng chỉ cần nhập thông tin, hệ thống sẽ tự động hiểu, phân tích và đề xuất–gợi ý bữa ăn phù hợp với sức khỏe và mục tiêu cá nhân.\nLợi ích và hoàn vốn đầu tư (ROI)\nTiết kiệm thời gian theo dõi dinh dưỡng, loại bỏ thao tác thủ công. Mang đến trải nghiệm AI thực tế, có tính cá nhân hóa cao. Tạo cơ sở dữ liệu chuẩn hóa cho nghiên cứu về AI trong lĩnh vực ẩm thực và cá nhân hóa bữa ăn. Chi phí thấp nhờ kiến trúc serverless. Dễ mở rộng và tái sử dụng mô hình cho các ứng dụng chăm sóc sức khỏe khác. ROI ước tính: hoàn vốn trong 6 tháng thông qua tiết kiệm thời gian phát triển và tái sử dụng mô hình AI đã có sẵn. Chi phí ước tính: khoảng 10–15 USD/tháng. 3. Kiến trúc giải pháp Nền tảng được xây dựng hoàn toàn trên mô hình AI-as-a-Service kết hợp AWS Serverless, đảm bảo hiệu năng cao, bảo mật và khả năng mở rộng linh hoạt. Dữ liệu dĩnh dưỡng về lượng calo của các món ăn được thu thập lưu trữ trong Amazon DynamoDB, sau đó sẽ gợi ý bữa ăn dựa phù hợp với lượng tính toán Calo mục tiêu. Amazon Bedrock được sử dụng để phân tích xử lý ngôn ngữ tự nhiên của người dùng tra cứu Calo món ăn và lưu vào Amazon DynamoDB. AWS Amplify lưu trữ giao diện web Next.js và Amazon Cognito đảm bảo xác thực người dùng an toàn. Kiến trúc được trình bày chi tiết bên dưới:\nDịch vụ AWS sử dụng\nAWS Amplify: Triển khai và lưu trữ giao diện web của nền tảng (Next.js), kết nối CI/CD trực tiếp với GitLab để tự động build và deploy. Amazon Route 53 + AWS WAF + Amazon CloudFront: Tầng Edge bảo vệ và phân phối nội dung nhanh chóng, đảm bảo bảo mật và hiệu năng truy cập toàn cầu. Amazon Cognito: Quản lý xác thực người dùng, đăng nhập và phân quyền truy cập an toàn cho từng tài khoản. Amazon API Gateway: Cung cấp endpoint cho các tác vụ như GET /Recommendation, POST /Log, GET /Dashboard, kết nối trực tiếp với Lambda. AWS Lambda (Private Subnet): Xử lý logic ứng dụng, gọi Bedrock và DynamoDB thông qua các VPC Endpoint để đảm bảo bảo mật và hiệu năng. AWS Bedrock: Sinh mô tả món ăn, chuẩn hóa log bữa ăn bằng ngôn ngữ tự nhiên và lưu vào DynamoDB phục vụ gợi ý bữa ăn cá nhân hóa. Amazon DynamoDB: Lưu trữ dữ liệu người dùng, nhật ký ăn uống, mục tiêu calo, và dữ liệu gợi ý – đảm bảo khả năng mở rộng linh hoạt. AWS Secrets Manager: Bảo mật thông tin xác thực (API Key, Bedrock credentials) cho Lambda và dịch vụ backend. Amazon CloudWatch \u0026amp; AWS CloudTrail: Theo dõi log, truy cập và hiệu năng toàn hệ thống; hỗ trợ giám sát và khôi phục sự cố. Amazon S3: Lưu trữ log. AWS IAM: Quản lý phân quyền truy cập chi tiết giữa các dịch vụ và người dùng. Amazon VPC: Cách ly Lambda trong subnet riêng, đảm bảo kết nối an toàn nội bộ giữa Lambda – DynamoDB – Bedrock.\nThiết kế thành phần\nQuản lý người dùng: Amazon Cognito quản lý quyền truy cập của người dùng. Phân phối \u0026amp; Bảo vệ truy cập: Route 53 định tuyến tên miền, AWS WAF bảo vệ khỏi tấn công web (SQL Injection, DDoS) và CloudFront tăng tốc độ tải nội dung và phân phối toàn cầu. Giao diện web: Amplify lưu trữ ứng dụng Next.js. Ghi nhật ký \u0026amp; gợi ý bữa ăn: Người dùng nhập dữ liệu (text) lưu vào DynamoDB, Lambda gợi ý món ăn theo số tính toán Calo. Phân tích bữa ăn: Lambda gọi Bedrock xử lý thông tin bữa ăn bằng ngôn ngữ tự nhiên của user nhập vào, bóc tách và tìm nhật ký Calo của món và lưu lại DynamoDB nếu món mới. Hiển thị dashboard: Amplify hiển thị biểu đồ calo theo ngày/tuần/tháng sau khi user cập nhật bữa ăn. Xác thực \u0026amp; bảo mật: Cognito đảm bảo đăng nhập an toàn và quản lý user. Giám sát \u0026amp; theo dõi: Amazon CloudWatch theo dõi log, hiệu năng Lambda, AWS CloudTrail lưu lại lịch sử thao tác và truy cập dịch vụ. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nNghiên cứu và Thiết kế: Thiết kế pipeline AI + Cloud, kiểm tra tính khả thi và vẽ sơ đồ hệ thống AWS (5 Tuần đầu tiên). Tính toán chi phí và tối ưu giải pháp: Kiểm tra lại chi phí các dịch vụ trong kiến trúc để tối ưu chi phí (Tuần 6). Phát triển, Kiểm thử và triển khai: Lưu dữ liệu ban đầu, sau đó tạo giao diện wed với Next.js, kiểm thử các luồng tính năng API, tốc độ và vận hành sản phẩm (Tuần 7 - tuần 11). Yêu cầu kỹ thuật\nDữ liệu Calo món ăn: Thu thập dữ liệu ban đầu và dùng script AWS SDK (Boto3) để nạp vào DynamoDB. Nền tảng gợi ý quán ăn: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), S3 (bucket), Cognito. Kiến thức thực tế về AWS Serverless (Lambda, DynamoDB, API Gateway), thiết kế schema DynamoDB (PK, SK), và cách dùng Bedrock API. 5. Lộ trình \u0026amp; Mốc triển khai Thực tập (Tháng 1–3): Tháng 1: Học và làm chủ các dịch vụ AWS. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Theo dõi, cải tiến hệ thống gợi ý và mở rộng dữ liệu trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator. Hoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Amplify: 0.50 USD/tháng (~100 MB, traffic thấp).\nAWS Lambda: 0.20-0.30 USD/tháng ( 100.000 request/tháng, thời gian chạy trung bình \u0026lt;1s ).\nAmazon API Gateway: 0.10-o.20 USD/tháng ( 50.000 request REST API/tháng).\nAmazon DynamoDB: 0.10-0.30 USD/tháng ( 50 MB dữ liệu, ~20.000 request/tháng).\nAmazon S3 (lưu trữ log/back-up): 0.10 USD/tháng (\u0026lt;2GB).\nAWS Bedrock: 3,00-500 USD/tháng ( vài nghìn token/tháng).\nCloudWatch + CloudTrail + IAM etc: ~ 0.10-USD.\nAmazon Cognito: 0.00 USD/tháng ( \u0026lt;50 người dùng hoạt động (Free Tier)).\nTổng: ~4-6 USD/tháng, ~50-75 USD/12 tháng.\n7. Đánh giá rủi ro Ma trận rủi ro\nLỗi AI xử lý sai: Ảnh hưởng cao, xác suất thấp. Quá tải request: Ảnh hưởng trung bình, xác suất Thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Lỗi logic: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nSai lệch AI: Dùng \u0026ldquo;prompt engineering\u0026rdquo; kỹ lưỡng. Quá tải request API: Giới hạn truy cập qua API Gateway. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Logic: Điều chình code kĩ lưỡng với các hàm lambda. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Trải nghiệm người dùng nâng cao: Cung cấp một trợ lý bữa ăn \u0026ldquo;thông minh\u0026rdquo;, xóa bỏ mọi rào cản thủ công trong việc ghi log và chọn món.\nTích hợp AI thực tế: Ứng dụng Bedrock trong hệ thống sản phẩm hoàn chỉnh.\nTạo nền tảng dữ liệu dinh dưỡng: Có thể mở rộng, phục vụ nghiên cứu AI \u0026amp; y tế.\nKhả năng mở rộng: tích hợp thêm phân tích hình ảnh món ăn, chat AI coach, và ứng dụng di động.\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "1. Tạo IAM Role bằng Console có quyền cần thiết Tạo một IAM role tên bedrock và gán các quyền cần thiết để sử dụng Amazon Bedrock: quyền gọi mô hình/agent (bedrock:InvokeModel, bedrock:CreateAgent, bedrock:InvokeAgent), quyền truy cập S3 (đọc/ghi) để nạp tài liệu cho Knowledge Base, và quyền CloudWatch Logs để ghi nhật ký v.v.v.\nMẫu tài liệu để nạp vào knowledge base (PDF, văn bản, markdown, HTML) Chúng ta sẽ tạo 1 tài liệu giới thiệu Amazon Web Services (Text) Amazon Web Services (AWS) là nền tảng điện toán đám mây của Amazon, chính thức ra mắt vào năm 2006. Ban đầu, AWS được tạo ra nhằm giải quyết vấn đề nội bộ của Amazon: họ cần một hạ tầng có khả năng mở rộng linh hoạt để phục vụ hệ thống thương mại điện tử khổng lồ của mình. Khi nhận ra rằng các doanh nghiệp khác cũng gặp những khó khăn tương tự về hạ tầng CNTT, Amazon quyết định thương mại hóa nền tảng này và cung cấp nó như một dịch vụ đám mây. AWS ra đời với mục tiêu giúp tổ chức và doanh nghiệp giảm chi phí đầu tư máy chủ, triển khai ứng dụng nhanh hơn, và tận dụng hạ tầng theo nhu cầu thay vì phải tự vận hành trung tâm dữ liệu. Đây là tầm nhìn cốt lõi đằng sau mô hình “điện toán đám mây” hiện đại: đưa tài nguyên tính toán trở thành một loại dịch vụ tiện ích có thể dùng ngay, giống như điện và nước. Trong những năm tiếp theo, AWS phát triển thần tốc, từ vài dịch vụ cơ bản như lưu trữ (Amazon S3) và máy ảo (EC2) thành hệ sinh thái hơn 200 dịch vụ bao gồm máy chủ ảo, container, trí tuệ nhân tạo, lưu trữ dữ liệu, bảo mật, IoT và phân tích dữ liệu. Nhờ khả năng mở rộng toàn cầu với hàng chục Region và hàng trăm điểm Edge trên thế giới, AWS trở thành nền tảng cloud dẫn đầu thị trường. Mục tiêu dài hạn của AWS là mang đến một môi trường điện toán an toàn, linh hoạt và có thể đáp ứng mọi nhu cầu của người dùng — từ startup nhỏ cho đến các tập đoàn lớn. AWS hướng đến việc giúp doanh nghiệp tập trung vào phát triển sản phẩm, thay vì tốn thời gian vận hành hạ tầng. Đến nay, AWS được sử dụng bởi các công ty công nghệ hàng đầu, chính phủ, trường đại học và hàng triệu tổ chức trên toàn thế giới. AWS không chỉ là dịch vụ hạ tầng, mà còn trở thành nền tảng quan trọng thúc đẩy đổi mới trong các lĩnh vực như học máy, Big Data, AI generative với (Amazon Bedrock), và phát triển ứng dụng serverless. Nhờ đó, AWS đóng vai trò quan trọng trong việc hình thành thế hệ công nghệ hiện đại. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.4-s3-onprem/5.4.2-create-agent/",
	"title": "Tạo Agent",
	"tags": [],
	"description": "",
	"content": " Ở trang giao diện của Aws Bedrock mình chọn phía trái Agent Bạn hãy điền tên và kiến trúc cho Agent để cho nó hiểu ngữ cảnh Ví dụ tôi viết nó là nhân viên tư vấn của Aws . Nhưng trước khi có được câu trả lời như thế thì tôi phải nạp Knowledge base cho nó hiểu - Nội dung của Knowledge base Lưu ý bạn nên cấu hình theo nhu cầu và nên cấp quyền cần thiết cho nó\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Biết triển khai Amazon CloudWatch giám sát hệ thống Hiểu được quy trình AWS CloudTrail ghi lại toàn bộ theo dõi hoạt động chi tiết của API Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Amazon CloudWatch + Metrics + Logs + Alarms + Events + Dashboards + AWS X-Ray 10/11/2025 10/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành: + Tạo IAM Role, IAM policy và cấu hình EC2 Instance + Cấu hình CloudWatch metric , logs + Kích hoạt CloudWatch Alams + Cấu hình Dashboards + Dọn dẹp tài nguyên 11/11/2025 11/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu AWS CloudTrail + Trails + event: Read/Write/All + CloudTrail Insights 12/11/2025 12/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu AWS Amplify + Frontend + Backend + Storage + Authentication 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành:: Giám sát Lambda với CloudWatch và X-Ray + Host source code lên Amplify + Giám sát với CloudWatch: Gỡ lỗi với logs, tạo customer metric và tạo cảnh báo với Alarm + Giám sát với X-Ray + Dọn dẹp tài nguyên. 14/11/2025 14/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Triển khai cơ bản được hệ thống giám sát toàn diện với Amazon CloudWatch:\nMetrics: Phân biệt được Metrics mặc định (như CPU, Network) và Custom Metrics (như Memory usage, Disk space - những chỉ số AWS không tự động thu thập từ bên ngoài hypervisor). Biết cách cài đặt CloudWatch Agent để đẩy các chỉ số custom này từ EC2 lên CloudWatch. Quản lý Logs tập trung: Biết cách gom log từ nhiều nguồn (EC2 app logs, Lambda execution logs) về CloudWatch Logs Group để tra cứu. Alarms: Thiết lập được hệ thống cảnh báo (qua email/SMS với SNS) khi hệ thống gặp sự cố (CPU quá tải, disk đầy, hoặc ứng dụng trả về nhiều lỗi ). Dashboard quản trị: Xây dựng được bảng điều khiển trực quan hiển thị sức khỏe của toàn bộ hệ thống trên một màn hình duy nhất. Kiểm soát an ninh với AWS CloudTrail:\nPhân biệt rõ sự khác nhau cốt lõi: CloudWatch trả lời câu hỏi \u0026ldquo;Hệ thống hoạt động thế nào?\u0026rdquo;, còn CloudTrail trả lời câu hỏi \u0026ldquo;Ai đã làm gì với hệ thống?\u0026rdquo;. Biết cách theo dõi lịch sử API calls để phục vụ mục đích bảo mật và điều tra sự cố . Ví dụ: Tìm ra ai đã xóa nhầm Security Group hoặc ai đã tắt EC2 instance. Hiểu về CloudTrail Insights để tự động phát hiện các hành vi bất thường trong tài khoản (ví dụ: đột biến số lượng API call để tạo resource). Triển khai ứng dụng nhanh chóng với AWS Amplify:\nHiểu Amplify là bộ công cụ giúp tăng tốc quy trình phát triển ứng dụng web/mobile, tự động hóa việc kết nối Frontend với các dịch vụ Backend (Auth, Storage, API). Thực hành thành công quy trình CI/CD đơn giản hóa: Đẩy code lên Git -\u0026gt; Amplify tự động build và deploy ra môi trường Hosting. Biết cách tích hợp việc giám sát (CloudWatch/X-Ray) ngay vào ứng dụng được deploy bởi Amplify để theo dõi trải nghiệm người dùng cuối. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Hiểu quy trình CI/CD và bộ công cụ AWS Code Series. Trải nghiệm được các dịch vụ Amazon AI Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu các dịch vụ orchestrator CI/CD trên AWS + AWS CodeCommit + AWS CodeBuild + AWS CodeDeploy + AWS CodePipeline 17/11/2025 17/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu về AWS Elastic Beanstalk + Application + Enviroment - Thực hành: Triển khai ứng dụng wed chạy trên AWS với Elastic Beanstalk + Tạo CloudFormation stack + Kết nối EC2 linux instance và cài đặt database + Kiểm tra máy chủ local để tải project + Triển khai trên ElasticBeanstalk + Cập nhật ứng dụng + Kiểm tra môi trường và truy vấn thông tin máy chủ EC2 + Dọn dẹp tài nguyên. 18/11/2025 18/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Cập nhật lại được các kiến thức về các Amazon Bedrock - Tìm hiểu rõ hơn về các dịch vụ pre-train AI service cũng như chi phí và cách sử dụng API 19/11/2025 19/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành: Sử dụng Amazon Polly + Cài đặt DynamoDB + Khám phá Amazon Polly + Tạo Speech và speech marks bằng AWS CLI + Tạo speech marks bằng AWS polly SDK dành cho java 20/11/2025 20/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: Sử dụng Amazon Rekognition + Tạo Cognito Identity Pool + Phát hiện đối tượng bằng Amazon Rekonition + Nhận diện khuôn mặt + Thử nghiệm ứng dụng tìm người + Gắn EBS volume 21/11/2025 21/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu quy trình \u0026ldquo;Software Supply Chain\u0026rdquo; trên AWS (CI/CD):\nHiểu rõ sự chuyển dịch từ việc deploy thủ công (copy file, SSH vào server) sang quy trình tự động hóa hoàn toàn với bộ AWS Code Series.\nNắm rõ vai trò của từng dịch vụ:\nAWS CodeCommit: Quản lý phiên bản mã nguồn (Git-based), nơi khởi nguồn của mọi thay đổi. AWS CodeBuild: Môi trường biên dịch và kiểm thử tự động (Unit Test), đảm bảo code \u0026ldquo;sạch\u0026rdquo; trước khi đi tiếp. AWS CodeDeploy: Tự động hóa việc đẩy code lên các đội hình server, giảm thiểu downtime và lỗi con người. AWS CodePipeline: \u0026ldquo;Nhạc trưởng\u0026rdquo; điều phối toàn bộ quy trình trên thành một dòng chảy liên tục. Nắm được platform as a Service với Elastic Beanstalk:\nHiểu được giá trị của việc thay vì phải tự cấu hình VPC, EC2, Load Balancer, Auto Scaling Group thủ công thì biết dùng Elastic Beanstalk để lo trọn bộ quá trình của việc này. Cập nhật tầm nhìn chiến lược về Generative AI Qua sự kiện: Generative AI with Amazon Bedrock\nHiểu sự chuyển dịch mô hình từ \u0026ldquo;Tự training model\u0026rdquo; sang \u0026ldquo;Sử dụng Foundation Models (FMs) qua API\u0026rdquo;. Nắm bắt được các khái niệm cốt lõi của Amazon Bedrock: Serverless AI, khả năng tích hợp Knowledge Base (RAG) và Agents để xây dựng ứng dụng AI doanh nghiệp bảo mật và riêng tư. Thực hành chuyên sâu tích hợp AI Services:\nVới Amazon Polly: Chuyển đổi văn bản thành âm thanh Biết chuyển đổi văn bản thành giọng nói đơn giản Biết xử lý Speech Marks (Metadata về thời gian thực của từ ngữ), một kỹ thuật tạo nhép giọng nói cho nhân vật ảo Biết cách sử dụng SDK (Java) để tích hợp Polly vào backend Với Amazon Rekognition: biết dùng Cognito Identity Pool để cấp quyền tạm thời cho ứng dụng truy cập trực tiếp vào Rekognition mà không cần hard-code Access Key Hiểu cách sử dụng API để giải quyết các bài toán thị giác máy tính phức tạp: Nhận diện khuôn mặt, phát hiện vật thể và định danh người. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Ôn tập hệ thống kiến thức serverless và AI Thiết kế chi tiết bảng database DynamoDB cho dự án và API Kiểm tra chi tiết về kết nối giữa các dịch vụ trong dự án Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập và thiết kế database (DynamoDB) + Xem lại kiến thức về Partition Key (PK) và Sort Key (SK) - Thực hành + Thiết kế Schema cho các bảng của dự án + Xác định các Access Pattern (Cách truy vấn dữ liệu) cho dự án. 24/11/2025 24/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Ôn tập và thiết kế API (API Gateway + Lambda): + Xem lại cách tạo REST API, Lambda Proxy Integration. + Liệt kê danh sách API endpoint cần thiết: POST, GET 25/11/2025 25/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Ôn tập luồng tích hợp AI với Bedrock + Xem lại các cách gọi API Bedrock + Xem lại các Prompt Engineering cơ bản 26/11/2025 26/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Ôn tập bào mật và xác thực (Cognito + IAM ) + Xem lại luồng xác thực User Login -\u0026gt; Nhận Token -\u0026gt; Gửi Token lên API Gateway. + Xem lại IAM Policy về cách cấp quyền tối thiểu 27/11/2025 27/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Ôn lại các cách giám sát hệ thống và vận hành + Xem lại CloudWatch để lên kế hoạch giám sát khi dự án chạy. + Xem lại Boto3 + Lập kế hoạch các bước triển khai dự án 28/11/2025 28/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hoàn thiện Schema Design cho DynamoDB:\nThiết kế bảng dữ liệu cụ thể, tối ưu cho việc truy xuất dữ liệu Xác định rõ ràng giao diện kết nối:\nĐịnh nghĩa rõ input/output cho các hàm Lambda.\nNắm cách dùng thư viện boto3 để kết nối các \u0026ldquo;mảnh ghép\u0026rdquo; AWS lại với nhau.\nChuẩn bị sẵn sàng kịch bản cho AI (Prompt Strategy) để test Bedrock đúng như mong đợi\nHiểu rõ luồng đi của Identity (Danh tính) từ Cognito qua API Gateway xuống Lambda.\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Trong quá trình tìm hiểu và học về các dịch vụ của AWS tôi cũng dịch qua các bài Blog để nâng cao kiến thức:\nBlog 1 - How a Customer Reduced Total Cost of Ownership (TCO) by 28% for Storage with Amazon FSx for NetApp ONTAP Blog này trình bày cách một tổ chức đa chi nhánh tối ưu hóa lưu trữ bằng Amazon FSx for NetApp ONTAP. Kiến trúc sử dụng FlexCache, SnapMirror và Multi-AZ giúp cải thiện hiệu năng truy cập, đơn giản hóa vận hành và giảm 28% tổng chi phí sở hữu (TCO) so với on‑premises.\nBlog 2 - Automating vector embedding generation in Aurora PostgreSQL with Bedrock Blog này hướng dẫn cách tự động sinh vector embeddings cho dữ liệu PostgreSQL sử dụng Aurora + pgvector + Bedrock. Bài viết trình bày nhiều chiến lược (triggers, Lambda đồng bộ/bất đồng bộ, SQS batch, pg_cron), phân tích ưu nhược điểm về độ trễ, tính đồng bộ, khả năng mở rộng và hướng dẫn thiết kế pipeline embedding tối ưu cho ứng dụng AI.\nBlog 3 - Group database tables under AWS Database Migration Service tasks for PostgreSQL source engine Blog này giải thích cách phân tích metadata PostgreSQL và đặc tính bảng để nhóm bảng hợp lý vào các AWS DMS task. Hướng dẫn giúp cân bằng tải, giảm độ trễ CDC, xử lý bảng lớn, bảng LOB hoặc thiếu PK/UK, và đưa ra best practice để migration dữ liệu quy mô lớn hiệu quả.\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.3-vpc-to-internet/",
	"title": "Khám phá Bedrock Console",
	"tags": [],
	"description": "",
	"content": " Trong phần này, bạn sẽ khám phá Amazon Bedrock Console và thực hiện các kiểm thử nhanh trong Playground để đánh giá cả chất lượng và chi phí của các mô hình. Trước khi chọn model cho môi trường production, hãy đo lượng token trung bình, so sánh phản hồi giữa các model, và ước tính chi phí để chọn mô hình phù hợp với ngân sách. Nội dung Khám phá Bedrock "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Cloud Day\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Generative AI with Amazon Bedrock\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.4-s3-onprem/",
	"title": "Thiết kế Agent",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, chúng ta sẽ tìm hiểu cách thiết kế một AI Agent hoạt động trên nền tảng Amazon Bedrock. Mục tiêu chính của chương là giúp bạn hiểu được Agent là gì, cách nó xử lý yêu cầu của người dùng, và tại sao Agent đóng vai trò quan trọng trong việc xây dựng các ứng dụng AI hiện đại.\nỞ phần tổng quan này, chúng ta sẽ phác thảo các thành phần quan trọng trong quá trình thiết kế một Agent, bao gồm cách xác định nhiệm vụ của Agent, mô tả hành vi mong muốn, cấu trúc workflow, lựa chọn mô hình nền tảng (Foundation Model), cũng như những nguyên tắc cần tuân thủ để Agent hoạt động ổn định và chính xác. Phần này cũng giới thiệu cách Agent tương tác với dữ liệu doanh nghiệp và tích hợp với các dịch vụ AWS nhằm triển khai vào môi trường thực tế.\nNội Dung Tạo Knowledge base Tạo Agent "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.5-policy/",
	"title": "Thử nghiệm ở on premise",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ thực hiện triển khai và thử nghiệm mô hình AI trong môi trường on-premise (tại chỗ). Đây là bước quan trọng để đánh giá tính khả thi và hiệu suất của hệ thống trong điều kiện thực tế trước khi đưa vào sản xuất 1.\nChúng ta sẽ kết nối qua python (boto3) Đầu tiên ta phải biết vùng của mình , Agent ID , Aliases Id\nPhải có acesskey Id , secret key : Lưu ý không thể để lộ 2 key này , nếu không sẽ bị người ngoài dùng dịch vụ và mình sẽ bị mất tiền\nThử promt xem có trả về kết quả hay không nếu có thì coi như đã thành công . "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "XÂY DỰNG AI AGENT VỚI AWS BEDROCK Tổng quan Amazon Bedrock: Amazon Bedrock là một dịch vụ AI/ML được quản lý hoàn toàn (fully managed) do AWS cung cấp, cho phép doanh nghiệp dễ dàng truy cập và sử dụng các mô hình nền tảng (Foundation Models – FM) hàng đầu như Claude, Llama, Stable Diffusion, Amazon Titan… mà không cần xây dựng hạ tầng AI phức tạp.\nChúng ta có thể gọi các mô hình này thông qua Bedrock API hoặc Bedrock console mà không cần tự triển khai hạ tầng AI.\nAI Agents thực hiện các nhiệm vụ nhiều bước bằng cách điều phối các tương tác giữa các Mô hình nền tảng, Nguồn dữ liệu và các ứng dụng phần mềm doanh nghiệp.\nNội dung Tổng quan về workshop Chuẩn bị môi trường AWS Khám phá Bedrock Console Thiết kế Agent AI cơ bản Kiểm tra và triển khai Dọn dẹp tài nguyên "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong workshop này!\nTrong workshop này, bạn đã học về AI Agent với bedrock trên Aws và thử bằng python (boto3) .\nDọn dẹp Điều hướng đến AWS Bedrock trên phía trái của bảng điều khiển . Chọn Agent . Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Điều hướng đến AWS Bedrock trên phía trái của bảng điều khiển . Chọn vào Knoweledge Base .Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo; Xóa IAM Role không còn dùng "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Vietnam từ 08/09/2025 đến 12/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia AWS First Cloud Journey (FCJ) học tập và trao đổi kiến thức với bạn bè và anh / chị mentor và các sự kiện của AWS, qua đó cải thiện kỹ năng lập trình, phân tích, dịch blog, viết báo cáo, giao tiếp, best practice với các dịch vụ cơ bản của AWS.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật và tính chủ động trong việc trao đổi với mọi người về công việc Cần cải thiện và nâng cao tư duy giải quyết vấn đề, phát triển hơn về kỹ năng trình bày và phát biểu trước đám đông Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Tôi muốn chia sẻ một vài ý kiến cá nhân về trải nghiệm khi tham gia chương trình First Cloud Journey, dựa trên những gì mình đã trải qua trong hành trình mới đầy thử thách này. Chương trình đã giúp tôi học hỏi và trải nghiệm được nhiều kiến thức hay và hấp dẫn.\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc trò chơi về kiến thức trong quá trình học để mọi người vừa hiểu nhau hơn vừa học hỏi lẫn nhau hiệu quả hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Các anh không chỉ giải đáp thắc mắc về mặt kỹ thuật mà còn định hướng tư duy giải quyết vấn đề. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nLà một sinh viên chuyên ngành AI, việc tham gia FCJ và tiếp cận sâu với AWS Cloud là một mảnh ghép hoàn hảo cho lộ trình sự nghiệp của mình. Công việc được giao không chỉ giúp củng cố kiến thức nền tảng về Lập trình/Dữ liệu mà còn mở ra tư duy mới về hạ tầng và triển khai ứng dụng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp. Những kinh nghiệm thực chiến từ Mentor chia sẻ là những bài học vô giá mà trường lớp khó có thể cung cấp đủ.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, chia sẻ và hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh. 6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có chính sách hỗ trợ thực tập sinh rất thỏa đáng, từ phụ cấp đến sự linh hoạt về thời gian làm việc để cân bằng việc học. Đặc biệt, giá trị lớn nhất mình nhận được là được tham gia các buổi đào tạo nội bộ và các workshop chia sẻ kiến thức với nhau.\nMột số câu hỏi khác Điều tôi hài lòng nhất trong thời gian thực tập? Đó là được các anh chị mentor và các bạn trong nhóm hỗ trợ hết mình trong hành trình lên mây từ con số 0 của mình. Mặc dù hành trình này hơi khó khăn nhưng nhờ những chia sẻ và sự giúp đỡ ấy đã giúp mình từ từ cải thiện và học được nhiều thứ mới quan trọng cho nghề nghiệp tương lai của mình. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Mình nghĩ là nên có lộ trình cụ thể để cho các bạn có thể tìm hiểu và học nhanh hơn và nhiều bạn cú tìm hiểu mãi mà bị mất phương hướng không biết mình đang làm gì. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Tôi sẽ giới thiệu bạn bè. Vì đây là môi trường lý tưởng để chuyển hóa kiến thức sách vở thành kỹ năng thực chiến để triển khai ý tưởng thành sản phẩm. Nếu bạn bè mình muốn thực sự hiểu \u0026ldquo;làm Cloud\u0026rdquo; là như thế nào chứ không chỉ là lý thuyết, FCJ là điểm bắt đầu tốt nhất. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Mình rất mong muốn có cơ hội tiếp tục đồng hành cùng công ty Góp ý khác (tự do chia sẻ): Em xin gửi lời cảm ơn chân thành đến các Mentor và Team FCJ đã kiên nhẫn và tận tâm dẫn dắt em trong suốt 3 tháng qua. Hành trình First Cloud Journey không chỉ cho em kiến thức mà còn cho em sự tự tin để theo đuổi con đường kỹ sư Cloud \u0026amp; AI chuyên nghiệp. "
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://baoxanhla.github.io/AWS_WORKSHOP_IPoG/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]